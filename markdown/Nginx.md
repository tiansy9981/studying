# Nginx

## 一、nginx是什么？

相信很多正在学习Linux或者已经在从事运维工作的朋友都有听过nginx,那它究竟是什么呢？为什么这么火？

首先nginx是由俄罗斯人发明的一款高性能的web服务器，它同早期的Apache，IIS，Lighttpd等都具有web服务器的功能，能够发布网站代码等资源，为用户提供信息资讯。但是nginx的功能不单单只是做为web服务器，它还可以用来做反向代理和负载均衡服务器，并且整体性能非常强大，在web前端服务器目前是企业的首选。

在国外的[Netcraft News][2]这个站点统计了全球最热门的网站所使用的web服务器，其中nginx目前一直稳居第一位：

![img](https://pic4.zhimg.com/80/v2-b9c1c75370accddfca5f779606e69caf_1440w.webp)

目前，我们国内基本上大多数的互联网企业门户站点也都采用的是nginx，包括

[阿里巴巴开源镜像站-OPSX镜像站-阿里云开发者社区developer.aliyun.com/mirror/](https://link.zhihu.com/?target=https%3A//developer.aliyun.com/mirror/)

[欢迎访问网易开源镜像站mirrors.163.com/](https://link.zhihu.com/?target=https%3A//mirrors.163.com/)

[清华大学开源软件镜像站 | Tsinghua Open Source Mirrormirrors.tuna.tsinghua.edu.cn](https://link.zhihu.com/?target=https%3A//mirrors.tuna.tsinghua.edu.cn)

等等。

**简单说明nginx就是一个性能很强、支持反向代理与负载均衡等功能的web中间件**

## 二、nginx能做什么？

### nginx可以做反向代理：

nginx的反向代理是nginx的是个非常重要的功能，它可以隐藏后端服务器的数量，并且保证后端服务器免受攻击；

### nginx可以做负载均衡：

nginx的负载均衡其实是反向代理的延伸，当单台后端服务器无法处理前端庞大的请求时，可以为后端多准备几台服务器，共同分摊流量，这就是负载均衡，也叫均衡负载；

### nginx可以做域名重定向：

重定向也是web服务器非常重要的功能，我来举一个例子：假设你们公司现在有一个域名，很多老用户已经习惯了是这个域名来访问你们的网站。但是你们公司经过改造，需要更换域名，这时就会面临丢失很多老用户的问题。那么这个问题通过nginxd的重定向就可以解决，我们只需要把访问老域名的流量重定向新域名就可以了。除了做域名重定向，还有内部重定向，比如用户访问到没有的资源，我们希望给用户返回指导用户或者首页。这时，就可以写内部重定向实现了。

### nginx可以做动静分离：

nignx的动静分离其实也是nginx的反向代理的功能，只是它很强大和特别，所以一般单独拿出来说。因为nginx处理静态资源的能力非常强，效率非常高。所以很多时候，我们会将用户请求的静态资源直接交由nginx代理服务器处理，然后把动态的应用程序代理到后端，给应用服务器处理，以此来提高用户体验；

### 其他

nginx还有很多强大的功能，比如做缓存服务器，邮件代理服务器，还可以做微服务网关等，具体功能需要配合使用其功能模块。

## 三、Nginx实现功能的原理

### 1、架构设计优势

#### Nginx的模块

Nginx的模块从结构上分为**核心模块、基础模块和第三方模块**：

**核心模块**：HTTP模块、EVENT模块和MAIL模块；核心模块是 Nginx 服务器正常运行必不可少的模块，提供错误日志记录 、配置文件解析 、事件驱动机制 、进程管理等核心功能；标准HTTP模块：提供HTTP协议解析相关的功能，比如：端口配置、网页编码设置、HTTP响应头设置等等；邮件服务模块：主要用于支持 Nginx 的 邮件服务 ，包括对 POP3 协议、 IMAP 协议和 SMTP协议的支持

**基础模块**：HTTP Access模块、HTTP FastCGI模块、HTTP Proxy模块和HTTP Rewrite模块，可选HTTP模块：主要用于扩展标准的 HTTP 功能，让 Nginx 能处理一些特殊的服务，比如： Flash多媒体传输 、解析 GeoIP 请求、 网络传输压缩 、 安全协议 SSL 支持等

**第三方模块**：HTTP Upstream Request Hash模块、Notice模块和HTTP Access Key模块。

用户根据自己的需要开发的模块都属于第三方模块

**Nginx的模块从功能**上分为如下三类。

**Handlers（处理器模块）**。此类模块直接处理请求，并进行输出内容和修改headers信息等操作。Handlers处理器模块一般只能有一个。

**Filters （过滤器模块）**。此类模块主要对其他处理器模块输出的内容进行修改操作，最后由Nginx输出。

**Proxies （代理类模块）**。此类模块是Nginx的HTTP Upstream之类的模块，这些模块主要与后端一些服务比如FastCGI等进行交互，实现服务代理和负载均衡等功能。

![img](https://pic3.zhimg.com/80/v2-bba05f88f0c43d94d2189ab972c0e5d2_1440w.webp)

Nginx本身做的工作实际很少，当它接到一个HTTP请求时，它仅仅是通过查找配置文件将此次请求映射到一个location block，而此location中所配置的各个指令则会启动不同的模块去完成工作，因此模块可以看做Nginx真正的劳动工作者。通常一个location中的指令会涉及一个handler模块和多个filter模块（当然，多个location可以复用同一个模块）。handler模块负责处理请求，完成响应内容的生成，而filter模块对响应内容进行处理。

### **2.Nginx的进程模型**

![img](https://pic1.zhimg.com/80/v2-ffac1b616f662445617117c80c1d2f04_1440w.webp)

在工作方式上，Nginx分为单工作进程和多工作进程两种模式。在单工作进程模式下，除主进程外，还有一个工作进程，工作进程是单线程的；在多工作进程模式下，每个工作进程包含多个线程。Nginx默认为单工作进程模式。

![img](https://pic3.zhimg.com/80/v2-96455d452639a31fdb8500774f6559ce_1440w.webp)

上图我们启动Nginx之后，查看进程，会看到一个master进程和一个worker进程，其中master进程只有一个，工作进程至少一个或以上，这里只有一个因为我们在nginx.conf设置了worker_processes=auto，这样nginx会自动根据核心数为生成对应数量的worker进程。

Master进程：

- 管理 Worker 进程
- 对外接口：接收外部的操作（信号）
- 对内转发：根据外部的操作的不同，通过信号管理 Worker
- 监控：监控 Worker 进程的运行状态，Worker 进程异常终止后，自动重启 Worker 进程

我们要控制nginx，只需要通过kill向master进程发送信号就行了。比如kill -HUP pid，则是告诉nginx，从容地重启nginx，我们一般用这个信号来重启nginx，或重新加载配置，因为是从容地重启，因此服务是不中断的。master进程在接收到HUP信号后是怎么做的呢？首先master进程在接到信号后，会先重新加载配置文件，然后再启动新的worker进程，并向所有老的worker进程发送信号，告诉他们可以光荣退休了。新的worker在启动后，就开始接收新的请求，而老的worker在收到来自master的信号后，就不再接收新的请求，并且在当前进程中的所有未处理完的请求处理完成后，再退出。当然，直接给master进程发送信号，这是比较老的操作方式，nginx在0.8版本之后，引入了一系列命令行参数，来方便我们管理。比如，./nginx -s reload，就是来重启nginx，./nginx -s stop，就是来停止nginx的运行。如何做到的呢？我们还是拿reload来说，我们看到，执行命令时，我们是启动一个新的nginx进程，而新的nginx进程在解析到reload参数后，就知道我们的目的是控制nginx来重新加载配置文件了，它会向master进程发送信号，然后接下来的动作，就和我们直接向master进程发送信号一样了。

Worker进程

- Worker 进程都是平等的
- 实际处理：网络请求，由 Worker 进程处理。
- Worker 进程数量：在 nginx.conf 中配置，一般设置为核心数，充分利用 CPU 资源，同时，避免进程数量过多，避免进程竞争 CPU 资源，增加上下文切换的损耗。

当我们提供80端口的http服务时，一个连接请求过来，每个进程都有可能处理这个连接，怎么做到的呢？首先，每个worker进程都是从master进程fork过来，在master进程里面，先建立好需要listen的socket（listenfd）之后，然后再fork出多个worker进程。所有worker进程的listenfd会在新连接到来时变得可读，为保证只有一个进程处理该连接，所有worker进程在注册listenfd读事件前抢accept_mutex，抢到互斥锁的那个进程注册listenfd读事件，在读事件里调用accept接受该连接。当一个worker进程在accept这个连接之后，就开始读取请求，解析请求，处理请求，产生数据后，再返回给客户端，最后才断开连接，这样一个完整的请求就是这样的了。我们可以看到，一个请求，完全由worker进程来处理，而且只在一个worker进程中处理。worker进程之间是平等的，每个进程，处理请求的机会也是一样的。当我们提供80端口的http服务时，一个连接请求过来，每个进程都有可能处理这个连接，怎么做到的呢？首先，每个worker进程都是从master进程fork过来，在master进程里面，先建立好需要listen的socket（listenfd）之后，然后再fork出多个worker进程。所有worker进程的listenfd会在新连接到来时变得可读，为保证只有一个进程处理该连接，所有worker进程在注册listenfd读事件前抢accept_mutex，抢到互斥锁的那个进程注册listenfd读事件，在读事件里调用accept接受该连接。当一个worker进程在accept这个连接之后，就开始读取请求，解析请求，处理请求，产生数据后，再返回给客户端，最后才断开连接，这样一个完整的请求就是这样的了。我们可以看到，一个请求，完全由worker进程来处理，而且只在一个worker进程中处理。

### **3.I/O模型**

由于进程是不可直接访问外部设备的，所以只能调用内核去调用外部的设备(上下文切换)，然后外部设备比如磁盘，读出存储在设备自身的数据传送给内核缓冲区，内核缓冲区在copy数据到用户进程的缓冲区。在外部设备响应的给到用户进程过程中，包含了两个阶段；由于数据响应方式的不同，所以就有了不同的I/O模型。

①、Blocking I/O 阻塞IO



![img](https://pic3.zhimg.com/80/v2-76cab976fc55c54d5ad9b81966c865de_1440w.webp)



最传统的一种IO模型，即在读写数据过程中会发生阻塞现象。

当用户线程发出IO请求之后，内核会去查看数据是否就绪，如果没有就绪就会等待数据就绪，而用户线程就会处于阻塞状态，用户线程交出CPU。当数据就绪之后，内核会将数据拷贝到用户线程，并返回结果给用户线程，用户线程才解除block状态。

举个栗子：我们去餐厅吃饭的时候，由于人多，服务员写了个排队号给我们，这个时候我们想去逛街，但是又怕刚去逛一会，就轮到我们吃饭了，所以只能坐在那等着叫号，这个过程中我们什么也不做，时间就浪费掉了。

②、Nonblocking I/O 非阻塞IO

![img](https://pic2.zhimg.com/80/v2-2f452274ade4c492d392c3966596bfb9_1440w.webp)



当用户线程发起一个read操作后，并不需要等待，而是马上就得到了一个结果。如果结果是一个error时，它就知道数据还没有准备好，于是它可以再次发送read操作。一旦内核中的数据准备好了，并且又再次收到了用户线程的请求，那么它马上就将数据拷贝到了用户线程，然后返回。
所以事实上，在非阻塞IO模型中，用户线程需要不断地询问内核数据是否就绪，也就说非阻塞IO不会交出CPU，而会一直占用CPU。

举个栗子：我们去餐厅吃饭，由于人多，服务员写了个排队号给我们，这个时候我们选择出去逛街，但是我们不敢逛太久，每次逛一会就过来问服务员到我们了没有，来来回回好多次，一直到轮到我们为止。

③、I/O multiplexing (select and poll) 多路复用IO

![img](https://pic4.zhimg.com/80/v2-c75dc3725593e749e85c961e991ed37f_1440w.webp)



在内核请求IO设备响应指令发出后，数据就开始准备，在此期间用户进程是阻塞的。数据从kernel buffer复制到用户进程的过程也是阻塞的。但是和阻塞I/O所不同的是，它可以同时阻塞多个I/O操作，而且可以同时对多个读操作，多个写操作的I/O函数进行检测，直到有数据可读或可写时，才真正调用I/O操作函数，也就是说一个线程可以响应多个请求。

举个栗子：我们去餐厅吃饭，由于人多，服务员给我们取了个排队号，同样的我们选择出去逛街，逛一会就回来看当前排队号，但是这个时候我们没有去问服务员，而是餐厅装了电子屏幕，上面显示当前叫号，这样轮到的人直接看电子屏幕就可以了。

④、Signal driven I/O (SIGIO) 信号驱动IO

![img](https://pic3.zhimg.com/80/v2-4c5182f75010fabf340262af1f747906_1440w.webp)



在信号驱动IO模型中，当用户线程发起一个IO请求操作，会给对应的socket注册一个信号函数，然后用户线程会继续执行，当内核数据就绪时会发送一个信号给用户线程，用户线程接收到信号之后，便在信号函数中调用IO读写操作来进行实际的IO请求操作。

举个栗子：我们去餐厅吃饭，由于人多，服务员给我们取了个排队号，餐厅除了装有电子屏幕之外，还使用了微信通知，只要轮到我们，微信会自动通知已经轮到我们吃饭了，这样我们就可以放心的去逛街，也不需要没逛一会就回来看一看，只需要等待通知就可以了。

⑤、Asynchronous I/O (the POSIX aio_functions) 异步IO

![img](https://pic3.zhimg.com/80/v2-a9f315d865cb646511557c6c57fb2caa_1440w.webp)

用户进程发起aio_read操作之后，给内核传递描述符、缓冲区指针、缓冲区大小等，告诉内核当整个操作完成时，如何通知进程，然后就立刻去做其他事情了。当内核收到aio_read后，会立刻返回，然后内核开始等待数据准备，数据准备好以后，直接把数据拷贝到用户控件，然后再通知进程本次IO已经完成。

举个栗子：我们怕去餐厅人太多，只想休息下，所以直接叫了个外卖，在家里休息着等送货员送到家里就可以了。

### **4.Nginx支持高并发原理**

Nginx 采用的是多进程（单线程） + 多路IO复用模型，就成了”并发事件驱动“的服务器。

- 基于线程，即一个进程生成多个线程，每个线程响应用户的每个请求。
- 基于事件的模型，一个进程处理多个请求，并且通过epoll机制来通知用户请求完成。
- 基于磁盘的AIO（异步I/O）
- 支持mmap内存映射，mmap传统的web服务器，进行页面输入时，都是将磁盘的页面先输入到内核缓存中，再由内核缓存中复制一份到web服务 器上，mmap机制就是让内核缓存与磁盘进行映射，web服务器，直接复制页面内容即可。不需要先把磁盘的上的页面先输入到内核缓存去。

## 四、Nginx如何实现其功能

### 1、基本安装

Nginx的安装可以分为两种：一种是安装包安装，通过安装相关依赖后，再安装nginx包。此安装方式简单便捷，较为通用只能实现较为通用的功能；另一种是通过源码包进行二进制安装，在安装前也需要安装相关编码依赖工具，再通过配置特定模块实现其定制功能的需求；

**！注：从1.9.11版本开始，nginx支持动态库，不需要安装额外的依赖使用所有的模块功能；**

### 2.文件结构

Nginx 配置文件由三部分组成。

```bash
...              #全局块

events {         #events块
   ...
}

http      #http块
{
    ...   #http全局块
    server        #server块
    { 
        ...       #server全局块
        location [PATTERN]   #location块
        {
            ...
        }
        location [PATTERN] 
        {
            ...
        }
    }
    server
    {
      ...
    }
    ...     #http全局块
}
```

- **第一部分 全局块**
  主要设置一些影响 nginx 服务器整体运行的配置指令。
  比如： worker_processes 1; ， worker_processes 值越大，可以支持的并发处理量就越多。

- **第二部分 events块**
  events 块涉及的指令主要影响Nginx服务器与用户的网络连接。
  比如： worker_connections 1024; ，支持的最大连接数。

- **第三部分 http块**
  http 块又包括 http 全局块和 server 块，是服务器配置中最频繁的部分，包括配置代理、缓存、日志定义等绝大多数功能。

- - **server块**：配置虚拟主机的相关参数。
  - **location块**：配置请求路由，以及各种页面的处理情况。

**nginx 负载均衡策略**

- **轮询**（默认）
  按请求的时间顺序依次逐一分配，如果服务器down掉，能自动剔除。
- **权重**
  weight 越高，被分配的客户端越多，默认为 1。比如：

```bash
            upstream myserver {   
              server 192.167.4.32:5000 weight=10;
              server 192.168.4.32:8080 weight=5;
            }
```

- **ip_hash**
  按请求 ip 的 hash 值分配，每个访客固定访问一个后端服务器。比如：

```bash
            upstream myserver { 
              ip_hash;  
              server 192.167.4.32:5000;
              server 192.168.4.32:8080;
            }
```

- **fair**
  按后端服务器的响应时间来分配，响应时间短的优先分配到请求。比如：

```bash
            upstream myserver { 
              fair;  
              server 192.167.4.32:5000;
              server 192.168.4.32:8080;
            }
```

### **什么是正向代理？**

正向代理，就是客户端将自己的请求率先发给代理服务器，通过代理服务器将请求转发给服务器。我们常用的VPN就是一种代理服务器，为了可以连上国外的网站，客户端需要使用一个可以连接外网的服务器作为代理，并且客户端能够连接上该代理服务器。

![img](https://pic2.zhimg.com/80/v2-d1da364c1b6c2f0024867c3f8ce49c59_1440w.webp)

#### **4. 什么是反向代理？**

反向代理与正向代理不同，正向代理是代理了客户端，而反向代理则是代理服务器端。在有多台服务器分布的情况下，为了能让客户端访问到的IP地址都为同一个网站，就需要使用反向代理。

![img](https://pic1.zhimg.com/80/v2-55476d2362c5706329c5693326b303bc_1440w.webp)

https://cloud.tencent.com/developer/beta/article/1654469

https://www.cnblogs.com/hukey/p/10498544.html