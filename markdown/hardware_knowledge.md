#  硬件相关知识

## 服务器

### 服务器硬件

**服务器硬件主要包括：处理器、内存、芯片组、I/O (RAID卡、网卡、HBA卡）、硬盘、机箱（电源、风扇）。**

**在硬件的成本构成上，CPU及芯片组、内存、外部存储是大头。**以一台普通的服务器生产成本为例，CPU及芯片组大致占比50% 左右，内存大致占比 15% 左右，外部存储大致占比10%左右，其他硬件占比25%左右。

![img](https://pic2.zhimg.com/80/v2-50eca6c4f36d29d6a1735de965d2d0ad_1440w.webp)

### 服务器固件

**服务器的固件主要包括BIOS或UEFI、BMC、CMOS，OS包括32位和64位。**

**1）BIOS**

**（Basic input/ Output System）**即基本输入输出系统，是服务器启动后最先运行的软件。它包括`基本输入输出控制程序`、`上电自检程序`、`系统启动自举程序`、`系统设置信息`。

BIOS是服务器硬件和OS之间的抽象层，用来设置硬件，为OS运行做准备。**BIOS设置程序是储存在BIOS芯片中的。BIOS的进化版本是UEFI（Unified Extensible FirmwareInterface），即统一的可扩展固定接口。**这种接口用于操作系统自动从预启动的操作环境，加载到一种操作系统上，从而使开机程序化繁为简，节省时间。

**2）BMC**

**（BaseboardManagementController）**即`基板管理控制器`，主要是对服务器进行监控和管理。BMC可以在服务器未开机的状态下，对机器进行固件升级、查看机器设备等。

**3）CMOS**

**(Complementary metal-oxide-semiconductor）**是电脑主机板上一块特殊的RAM芯片，是`系统参数存放`的地方。CMOS存储器用来`存储BIOS设定后的相关参数`。

**4）OS**

**（Operating system）**即操作系统，对服务器软硬件及数据资源进行管理调度。OS主要分为32位和64位，OS的位数版本决定了计算机处理器在RAM（随机存取储存器）处理信息的效率，64位版本比32位的可以处理更多的内存和应用程序。

### 服务器的分类

**服务器的分类标准是多元化的，目前主要可按产品形态、指令集架构、处理器数量、应用类型等对市场上的服务器进行分类。**

![img](https://pic3.zhimg.com/80/v2-734021c2b4a37154e4c6eea1d3182fae_1440w.webp)

### **按产品形态**

**服务器按产品形态，可以分为：塔式服务器、机架服务器、刀片服务器、机柜服务器等。**

![img](https://pic1.zhimg.com/80/v2-de2063df5da69a8993a8acb12c1d724c_1440w.webp)

**1）塔式服务器（ Tower Server）**

既常见的`立式和卧式机箱结构`的服务器，可放置在普通的办公环境，机箱结构较大，有较大的内部硬盘、冗余电源、冗余风扇的扩容空间，并具备较好的散热功能。塔式服务器密度低，多为单处理器系统（有少部分为双处理器系统）。`系统电源和风扇一般是单配`，`非冗余可靠性较低`。主要应用在企业官网、多媒体大流量APP、医疗成像、虚拟桌面基础架构（VD）等场景。

![img](https://pic4.zhimg.com/80/v2-eab548fab6bdf7f9189cc9eacf9d63e7_1440w.webp)

**2）机架式服务器（Rack Server）**

机架结构是传统电信机房的设备结构标准，`宽度为19英寸`，高度以单位“U”计算，`每“U”为1.75英寸（可换算成4.445cm`）。`通常有1U、2U、4U和8U之分，其中以1U和2U为主，其次是4U和8U`。近期市场也有3U和6U等高度的机架产品出现。机架服务器是一种外观按照统一标准设计的服务器，配合机柜使用。可以认为机架式是一种优化结构的塔式服务器，它的设计宗旨主要是为了尽可能减少服务器空间的占用，而减少空间的直接好处就是在机房托管的时候价格会便宜很多。主要应用在云计算、软件定义存储、超融合架构、CDN缓存、超算中心等场景。

![img](https://pic4.zhimg.com/80/v2-28ff83cea4d00d6da963716c448c88a7_1440w.webp)

**3）刀片式服务器（Blade Server）**

通常在一个机箱里可以插入数量不等的“刀片”，其中每一块“刀片”实际上就是一块服务器主板。刀片服务器通常只需要比机架服务器更少的机架空间，通过优化空间来提供更强的计算能力，是一种更高密度的服务器平台。一般包括刀片服务器、刀片机框（含背板）及后插板三大部分。不同厂商有不同高度的机框。各厂商机框皆为19英寸宽，可安装在42U的标准机柜上。主要应用在超算中心、异构计算、云计算平台、实时业务处理、商业智能分析及数据挖掘等场景。

![img](https://pic1.zhimg.com/80/v2-aebc63ad0991112a5f7e58737b0cb020_1440w.webp)

**4）机柜式服务器（Cabinet Server）**

是未来数据中心基础架构的核心形态和发展趋势。它集成计算、网络、存储于一体，以及面向不同应用时，可以部署不同的软件，提供一个整体的解决方案。机柜式服务器一般由一组冗余电源集中供电，散热方面由机柜背部风扇墙集中散热，功能模块和支撑模块相分离，通过供电、散热的整合，相比普通机架式服务器，运行功耗低、且可靠高效。此外，机柜式服务器无需繁琐拆装，维护便捷，能够轻松实现统一集中管理和业务的自动部署。主要应用在虚拟化、大数据分析、分布式存储、超算中心等快速一体化部署场景。

![img](https://pic4.zhimg.com/80/v2-0ed990554bf765eb1432faa02fe5c02f_1440w.webp)

### 按指令集架构

服务器按照指令集架构分类，主要包括：`CISC`服务器（Complex Instruction Set Computing）即复杂指令集计算，`RISC`服务器（Reduced Instruction Set Computing）即精简指令集计算，`EPIC`服务器（Explicitly parallel Instruction Computing）即显式并行指令计算。

![img](https://pic4.zhimg.com/80/v2-fb4ba33f95452f46ab7c3357b370588f_1440w.webp)

**1）CISC服务器**

**也被称为X86服务器，**采用Intel、AMD或其它兼容X86指令集的处理器芯片以及Windows操作系统的服务器，是目前主流的服务器架构。

**2）RISC服务器**

**RISC服务器基于RISC处理器，**目前主要包括IBM的Power和Power PC处理器，SUN和富士通合作研发的SPARC处理器，华为基于ARM架构级授权研发的鲲鹏920处理器。

**3）EPIC服务器**

EPIC服务器基于EPIC处理器，目前主要是Intel研发的安腾处理器等。

**使用RISC或EPIC架构的服务器又称非X86服务器**。包括：大型机、小型机和UNIX服务器，并且主要采用UNIX和其它专用操作系统。

![img](https://pic4.zhimg.com/80/v2-b9711932a8c5c5f495a74aca5707e47f_1440w.webp)

### 按处理器数量

**按照处理器的数量可将服务器分为：单路服务器、双路服务器、四路服务器、八路服务器等。**其中，“路”是指一台服务器内部的CPU个数，比如单路服务器内部CPU数量为1颗，双路服务器为2颗，以此类推。**目前主流的服务器是双路服务器。**

**多路服务器用到了对称多处理技术（Symmetrical Multi -Processing，简称SMP）**，是指在一个计算机上汇集了一组处理器，各CPU之间[共享内存](https://baike.baidu.com/item/共享内存?fromModule=lemma_inlink)子系统以及[总线结构](https://baike.baidu.com/item/总线结构?fromModule=lemma_inlink)。在这种架构中，一台电脑不再由单个CPU组成，而同时由多个处理器运行操作系统，而且共同使用内存和其他资源。虽然同时使用多个CPU，但是对用户来说，它们的表现就像一台单机一样。系统将任务分配给多个CPU，从而提高了整个系统的数据处理能力。在对称多处理系统中，系统资源被系统中所有的CPU共享，工作负载能够均匀地分配到所有可用处理器之上。

![img](https://pic3.zhimg.com/80/v2-e92d403a803a1f2a14f756fd373b06f2_1440w.webp)

### 按应用类型

**在不同的应用场景，对服务器的功能要求会有所侧重，按照其应用类型，可以分为文件服务器、数据库服务器、应用程序服务器。**

**1）文件服务器**

在计算机局域网中，以文件数据共享为目标，将供多台计算机使用的文件存储在一台服务器中，这台主机就被称为文件服务器。文件服务器相当于一个信息系统的大仓库，保证用户和服务器磁盘子系统之间快速数据传递。在该类型服务器的各个子系统中，对系统性能影响大小依次排列为网络系统、磁盘系统、内存容量、处理器性能。

**2）数据库服务器**

用于频繁的读取和索引数据的服务器，比如企业的财务系统、人事系统及各种管理系统均有类似需求。不同类型的企业对数据库服务器的要求不同，对于较大的企业，会涉及到分布式并发数据查询等问题，这对网络系统以及I/O的数据传输能力有比较高的要求；而对于较小的企业，并发用户相对较少，分布式查询需求不高，磁盘系统更为重要。

**3）应用程序服务器**

类似于文件服务器为很多用户提供文件一样，应用程序服务器让多个用户可以同时使用应用程序。在该类型服务器的各个子系统中，对处理器性能的要求会更高。

### X86/ARM之争

正如前文所述，按照指令集类型，服务器可以分为CISC服务器、RISC服务器、EPIC服务器。其中CISC服务器又被称为X86服务器，RISC和EPIC服务器又被统称为非X86服务器（也即Non-X86服务器）。从服务器的产业趋势来看，目前正形成双强的局面，其中X86服务器以Intel/AMD处理器为主导，而非X86服务器以ARM架构处理器为主导。双方各有优劣势，将长期共存。

![img](https://pic1.zhimg.com/80/v2-fafea0e33ab4202bdeb72e5e76446560_1440w.webp)

## 主板

什么是主板?主板就是电脑的骨骼，用来承载和连接各种电脑配件的配件。同时，也是处理器的家。普通家用PC的主板，更多的要求是在性能和功能上，而服务器主板是专门为满足服务器应用(高稳定性、高性能、高兼容性的环境)而开发的主机板。由于服务器的高运作时间，高运作强度，以及巨大的数据转换量，电源功耗量，[I/O吞吐量](https://baike.baidu.com/item/I%2FO吞吐量/451388?fromModule=lemma_inlink)，因此对服务器主板的要求是相当严格的。

### 主板的板型分类

主板的板型分类是在选择主板时首先要考虑的问题之一，主板的板型会决定整台PC的大小与相应的扩展性。

台式电脑的主板板型主要通过数主板的扩展插槽数来判断，以下是目前常见的主板板型。

![什么是主板？主板知识大科普](https://img4.xitongzhijia.net/allimg/170721/56-1FH1150005-50-water.jpg)

其中最常见的就是ATX（大板），M-ATX（小板），ITX。ATX主板比较适合安装在中塔机箱中，M-ATX比较适合中塔\迷你塔机箱，ITX主板比较适合HTPC机箱。E-ATX、XL-ATX、HTPX则相对较少有相关产品，产品更多的集中在旗舰级产品或服务器级产品。

### 主板芯片组和总线

服务器的核心是主板（不应该是CPU么？😀），而主板的核心是`芯片组`。所以芯片组对于服务器而言十分重要。现在市场上绝大多数的服务器芯片组都是`英特尔的芯片组`；

![2019090814021365.png](https://img-blog.csdnimg.cn/img_convert/004007b20f52a68196a266c3cbdca5c2.png)

服务器主板图

![20190908135451876.png](https://img-blog.csdnimg.cn/img_convert/04a1a7eeb9122a596b714cb6d1236045.png)

服务器主板[架构](https://so.csdn.net/so/search?q=架构&spm=1001.2101.3001.7020)图

如果把服务器比作一个人，那么CPU就是它的大脑，总线就是它的神经结构，芯片组则是他的神经中枢。

> **`芯片组决定了：`**
>
> - CPU的和内存的类型
> - 主板总线频率 / 带宽
> - 扩展插槽的种类和数量
> - 扩展接口的种类和数量
> - 总线是计算机组件用来传输数据的“道路”。

### 南桥与北桥

我们的主板上有两个很重要的芯片，分别叫北桥芯片组、南桥芯片组，它们的作用是什么呢？要知道早期的制造工艺相对粗糙，晶体管的数量相对偏少，因此曾经的处理器集成度较低，必须要由主板芯片组来承担大量功能，芯片组分为南桥芯片组和北桥芯片组两部分，其中的`北桥负责CPU与内存的数据交换、图形处理、CPU与PCIE数据交换`，`南桥则负责系统的输入输出功能`。

所以`北桥芯片还有个名字叫“图形与内存控制器”`，`南桥叫“输入/输出控制器”`。`北桥芯片组因为与CPU联系密切所以它在主板靠近CPU的位置`，而`南桥芯片则在远离CPU的位置`，所以我们是很好分辨北桥南桥的。

现在的CPU制造工艺越来越先进，集成度越来越高，`内存控制器已被集成到CPU里，就连显卡也被收进CPU了`（就是我们所说的核显，服务器芯片一般没有核显），而`PCIE控制器收归南桥管理`了，因此`北桥芯片组的功能被瓜分了`，所以现在的Intel芯片组把北桥取消掉只剩南桥了，而AMD也只有早期的主板还保留着北桥和南桥。

因为北桥已经没有了所以我们所讲的`芯片组就指的是南桥芯片组`，**南桥芯片组的功能是什么？它在整个电脑中起到什么作用呢？**给大家详解一下吧。

讲之前先说下PCIE，PCIE是一种高速传输总线，它即是接口也是通道，既然这么快为什么不让所有的设备都使用这个接口或是总线呢？按理说这样电脑所有的设备能更快才对吧！

其实理论确实是这样，其主要问题还是受制于成本和市场，PCIE作为一种超高速串行总线为了达到飞快的速度因此他的频率设置的非常的高，而高频的总线对线路设计的要求是非常非常高的，所以PCIE总线对于主板的布线来说是一个非常大的考验！为了能装下这种高速总线不得不把主板做成多层用来解决高频总线带来的各种需要。比如X570为了能支持PCIE4.0华硕的主板起步都6层了！而且主板的的用料也比之前的X470提高了一大截，这也解释了为什么X570的主板比X470要贵出很多的原因了。

PCIE是直接连接在CPU的PCIE控制器上，所以才能保证它的延迟非常非常的低、速度非常非常的快。只是PCIE控制器能提供的PCIE通道的数量是有限度的，CPU同样也要考虑电路的设计成本，而我们电脑上有这么多的设备都要去走PCIE通道去连接CPU，这对主板的布线来说简直是一个地狱级的挑战！但是CPU也没有必要实时的去和所有的外围设备通信，这时候呢就需要有一个可能代替CPU与设备通信的角色，这个角色就是南桥芯片组。

南桥芯片组一般位于主板的右下角，一般来说用AMD的芯片组的主板会给南桥芯片组加装一个风扇用于散热，所以我们要找到它是很容易的。而Intel的芯片组发热相对较低通常不需要配备风扇而是在上面放置一块铝质散热鳍片用来帮助散热。

（Z390主板南桥芯片的位置）

![img](https://pic1.zhimg.com/80/v2-a14ad3b5a8790aa73b40005ada0ca078_1440w.webp)

#### 南桥

**南桥**（英语：Southbridge）是基于[个人电脑](https://zh.wikipedia.org/wiki/个人电脑)[主板](https://zh.wikipedia.org/wiki/主板)[芯片组](https://zh.wikipedia.org/wiki/芯片组)架构中的其中一枚[芯片](https://zh.wikipedia.org/wiki/芯片)。南桥设计用来处理低速信号，通过[北桥](https://zh.wikipedia.org/wiki/北桥)与[中央处理器](https://zh.wikipedia.org/wiki/中央處理器)联系。各[芯片组](https://zh.wikipedia.org/wiki/晶片組)厂商的南桥名称都有所不同，例如[英特尔](https://zh.wikipedia.org/wiki/英特爾)称之为[I/O路径控制器](https://zh.wikipedia.org/wiki/I/O路徑控制器)（ICH）或[平台路径控制器](https://zh.wikipedia.org/wiki/平台路徑控制器)（PCH），[NVIDIA](https://zh.wikipedia.org/wiki/NVIDIA)的称为MCP，[ATI](https://zh.wikipedia.org/wiki/ATI)的称为IXP/SB，[AMD](https://zh.wikipedia.org/wiki/AMD)用[FCH](https://zh.wikipedia.org/wiki/AMD_FCH)（Fusion Control Hub）代表[AMD APU](https://zh.wikipedia.org/wiki/AMD_APU)/[AMD Ryzen](https://zh.wikipedia.org/wiki/AMD_Ryzen)/[AMD EPYC](https://zh.wikipedia.org/wiki/EPYC)的南桥芯片。

南桥包含大多数周边设备接口、多媒体控制器和通信接口功能。例如[PCI](https://zh.wikipedia.org/wiki/PCI)/低速[PCIe](https://zh.wikipedia.org/wiki/PCIe)（如PCIe x1）控制器、[ATA](https://zh.wikipedia.org/wiki/高技術配置)/[SATA](https://zh.wikipedia.org/wiki/SATA)控制器、[USB](https://zh.wikipedia.org/wiki/USB)控制器、网络控制器、音效控制器。

中高阶的南桥可以提供“Fake RAID”功能。英特尔的ICHxR系列南桥支持[英特尔快速存储技术](https://zh.wikipedia.org/wiki/英特尔快速存储技术)。

南桥芯片组和CPU一样是一块硅芯片，它的作用就是帮助CPU与外围设备进行交互的，具体怎么做呢？在电脑里所有设备中内存对于速度要求是非常高的，所以内存是直接跟CPU对接的，同样对速度要求高的还有PCIE也是直接跟CPU对接。其它的设备比如声卡、网卡、固态硬盘、机械硬盘、USB等等这种对实时通讯要求不是很高的设备就全部接入南桥芯片组，南桥收集好了数据后再传输给CPU处理。这就是南桥芯片组的工作原理。

附一张Intel官网提供的Z390芯片组的结构图，因为是英文的我就给注释了一下，如果想看其它的大家可以去官网下载。

![img](https://pic3.zhimg.com/80/v2-fe9d3a5c97b5603674af69ccec4b0cba_1440w.webp)

看了结构图大家有没有发现一个问题，直连CPU的PCIE3.0通道一共有16条，插法分别是X16/X8+X8/X8+X4+X4，目前的显卡基本都是PCIE X16的，一个显卡就把直连CPU的16条通道全占满了，这时候如果再插一个M.2 PCIE X4的固态的话它跟显卡会不会抢带宽呢？我可以肯定是告诉大家M.2和显卡使用的PCIE通道不是共享的，因为M.2用的PCIE通道不是直连CPU的，M.2用的是来自南桥芯片组的24条非直连的PCIE3.0通道。所以显卡和M.2一个是用的CPU的PCIE一个是用的南桥的PCIE是一点也不冲突的。

回到Intel的结构图上，在CPU与南桥之间是通过DMI3.0总线来连接的，这个总线其实就是PCIE3.0X4，而在AMD是结构图上就直接标上PCIE了，也就是说CPU和南桥之间的数据带宽上限就是PCIE3.0X4（4Gb/S），这也就解释了为什么市场上的固态硬盘包括M.2接口的基本用的是PCIE3.0X4的总线了，因为M.2是用的南桥的PCIE通道所以它的速度是不可能超过CPU和南桥之间的带宽的。也就是说所有连接到南桥的设备其速度都无法超过4GB/S，所以当前最快的民用M.2固态硬盘970PRO顺序读写也只能卡在3.6GB/S左右，无法突破4GB/S。

（AMD主板结构图）



![img](https://pic2.zhimg.com/80/v2-d9e3b682494eed8dcbc098b31d077019_1440w.webp)

有的人可能会有疑问，在Intel的架构图上明明可以清楚看到南桥芯片有24条非直连的PCIE3.0通道，为什么CPU与南桥之间只开放PCIE3.0X4这么小的通道呢？这是因为连接到南桥的所有设备一般来说很难做到全部同时工作，多数情况下只有一两个设备在传输，即便好几个设备同时从南桥往CPU传输数据这几个设备也不可能同时都是满载状态。虽然只有PCIE3.0X4的速度，但是南桥上的设备同时满载的时候是非常少的，以目前的情况来看是完全够用了。



### 芯片架构的发展

芯片架构可以分为单芯片架构和双芯片架构，以前主要是双芯片架构。

![20190908182946831.png](https://img-blog.csdnimg.cn/img_convert/7dcd9734766c51114a8fcab33e835d07.png)

**双芯片架构**

其中双芯片就是`MCH`和`ICH`，MCH是[内存](https://so.csdn.net/so/search?q=内存&spm=1001.2101.3001.7020)控制中枢，也称为`北桥芯片`。ICH是输入输出控制中枢，也称为`南桥芯片`。北桥芯片主要给CPU、内存等设备提供支持。南桥芯片主要对键盘、接口等外围设备提供支持。

![20190908184026218.png](https://img-blog.csdnimg.cn/img_convert/78547fa17b54a72bc28c2566a248c95b.png)

**单芯片架构**

现在的服务器一般都使用单芯片架构，在单芯片架构中，以前的北桥芯片被集成到了CPU中，南桥芯片也不再叫做ICH，就只有一个PCH，PCH是平台管理器中枢。

### 总线的种类

![20190908185015968.png](https://img-blog.csdnimg.cn/img_convert/a5aa59e411cb609277a06b7ef8b1e160.png)

如图所示

- CPU与CPU之间通过QPI总线进行通信
- CPU与PCI-E设备通过PCIE总线进行通信
- CPU和PCH通过DMI总线进行通信
- PCH芯片和USB设备之间通过USB总线进行通信
- PCH芯片和PCI设备通过PCI总线进行通信
- PCH芯片和PCI-E设备通过PCIE总线进行通信
- PCH芯片和SATA硬盘之间通过SATA总线进行通信
- PCH芯片和SAS硬盘之间通过SAS总线进行通信
- PCH和网卡之间使用PCIE总线进行通信
- BMC与其他设备通过SPI总线进行通信

**FSB总线( Front Side Bus )前端总线,用来连接CPU和内存控制中枢(北桥芯片)。**

**QPI总线( Quick Path Interconnec )快速通道互联,是CPU和CPU之间以及CPU和IOH芯片之间的一种高速点对点互联总线。**

**DMI总线( Direct Media Interface )直接媒体接口,是北桥芯片( MCH )和南桥芯片(ICH )以及CPU和PCH芯片之间的点对点互联总线。**

**PCI总线( Peripheral Component Interconnect )外围组件互联,是一个用于将设备附加到主板上的计算机总线。**

**PCI-E总线( PCI Express) :** 采用了目前业内流行的点对点串行连接,比起PCI以及更早期的计算机总线的共享并行架构,每个设备都有自己的专用连接,不需要向整个总线请求带宽,而且可以把数据传输率提高到一个很高的频率,达到PCI所不能提供的高带宽。在工作原理上PCI Express与并行体系的PCI没有任伺相似之处,它采用串行方式传输数据,依靠高频率来获得高性能。

其中，FSB总线、QPI总线、DMI总线是系统总线；PCI总线和PCIE总线是系统总线。

### FSB总线与QPI总线的区别

**`FSB总线`**： 是`Front Side BUS`的英文缩写，中文叫做**前端总线**，在双芯片架构中是将CPU连接到北桥芯片的系统总线，它是CPU和外界交换数据的主要通道。前端总线的数据传输能力对计算机整体性能影响很大，CPU就是通过前端总线( FSB )连接到北桥芯片，进而通过北桥芯片和内存、显卡交换数据的，如果没有足够快的前端总线，再强的CPU也无法明显提高计算机的整体速度。在CPU集成了内存控制器后的单芯片架构，抛弃了沿用多年的的FSB , CPU可以直接通过内存控制器访问内存资源，而不是以前繁杂的”前端总线一北桥- -内存控制器”模式。

**`QPI总线`**：是`CPU与CPU之间`, CPU与IOH芯片之间交换数据的高速通道, QPI总线可以实现多颗CPU之间的直接互联,而无须像以前那样还要再经过FSB进行连接，从而大幅提升整体系统性能。

![20190908192349745.png](https://img-blog.csdnimg.cn/img_convert/e991bd138f23c5d4e13b9a7bdceb788d.png)

### PCI、PCI-X、PCI-E总线

![20190908193029127.png](https://img-blog.csdnimg.cn/img_convert/267e07f54991186df94eb39dd8502f6a.png)

`PCI`和`PCI-X`是并行总线, `PCI-E`是串行总线，前面两者采用并行方式传输数据，后者采用串行方式传输数据。它们的总线带宽计算方法也是不一样的。目前，PCI-E已经基本取代了PCI和PCI-X

由上图可以看出，`PCI-E虽然是串行方式传输，但是因为其传输频率非常高，即便是只有1位也比PCI、PCI-X传输快。`因此，PCI总线的发展是由并行低频向串行高频发展。

### PCI-E总线

1.PCI-E总线支持向下兼容，PCI-E3.0可以兼容PCI-E2.0（现在5.0却不能直接支持4.0，只是插口能兼容。。）

2.PCI-E插槽可以支持短的PCI-E的插卡。插槽如下，分为x1,x4,x8,x16四种插槽和插卡

![20190908193957472.png](https://img-blog.csdnimg.cn/img_convert/d92fd06fa0bf8e1fcb5a969fce450d2f.png)

#### PCIe概述：

PCI-Express(peripheral component interconnect express)是一种高速串行计算机扩展总线标准，由Intel在2001年的IDF上提出，旨在替代旧的PCI，PCI-X和AGP总线标准。

PCIe属于高速串行点对点双通道高带宽传输，所连接的设备分配独享通道带宽，不共享总线带宽，主要支持主动电源管理，错误报告，端对端的可靠性传输，热插拔以及服务质量(QOS)等功能。

![img](https://pic3.zhimg.com/80/v2-4abd58973df6acba550923460badf70e_1440w.webp)

#### PCIe命名及版本对比：

PCIe命名一般由两个部分组成，分别是PCIe接口版本和可使用通道数。

![img](https://pic4.zhimg.com/80/v2-ff5d16018831c7e4263b02127ec72b7b_1440w.webp)

A.0 指PCIe接口版本，版本越高，接口传输速率越高

B 一般指该槽位使用数据带宽，也就是最大可使用PCIe通道数，可使用通道数越多，速度越快

![img](https://pic2.zhimg.com/80/v2-03e4bfe636492ef92fa8c6e0a62bbccd_1440w.webp)

现阶段服务器大多使用的是PCIe 3.0版本，部分高端旗舰机型可支持PCIe 4.0版本。

#### PCIe外观对比

PCIe接口根据总线位宽不同而有所差异，一个PCI Express连接可以被配置成x1， x2， x4， x8， x12， x16的数据带宽。

PCIe 各种位宽Device可以自由搭配使用，比如x1 的卡可以插到x8的插槽中使用， x8 的卡可以插到x16的插槽中使用，升级方便。

![img](https://pic1.zhimg.com/80/v2-1660a5e7b3ca5b6e9cce9a7d26f31a34_1440w.webp)

![img](https://pic1.zhimg.com/80/v2-f8a69aaf3bf348513f94b63744fc0e78_1440w.webp)

注意：不同PCIe插槽是由不同CPU进行控制。例如上图所示的B、C插槽，B插槽是由CPU1进行控制，C插槽是由CPU2进行控制。

#### PCIe常见问题

Q：主板上只有一个x16的插槽而且已经用了，还有个x16的RAID卡可以插在x8的插槽内吗？

A：可以，RAID卡将以x8的方式工作。实际上，你可以将任何PCIe卡插入任何PCIe插槽中， PCIe在链接training的时候会动态调整出双方都可以接受的宽度。

Q：PCIe 3.0的卡在PCIe2.0的槽位上能工作吗？

A：可以，会以2.0工作。反之，亦然。

Q：同一个主板，同一张卡，插在PCIe A上可以正常使用，而在PCIe B却无法识别？

A：此问题常出现在双路主板上，主板的PCIe接口分别由两个CPU控制。如果只上了一个CPU，那么另外一个CPU控制的PCIe通道是不通电的，自然不能识别。

#### 用PCIe进行链接的配件有哪些？

![img](https://pic2.zhimg.com/80/v2-360a87aecdb48d75149b99273c64468d_1440w.webp)

![img](https://pic3.zhimg.com/80/v2-f36cfa4a49043955a87fcb7cc0b1da3a_1440w.webp)

![img](https://pic4.zhimg.com/80/v2-3438671c74439db12e1b01f2d18bd097_1440w.webp)

## CPU

计算机根据CPU（Central Processing Unit）指令集的不同可以分为复杂指令集计算机（Complex Instruction Set Computer ）与简单指令集计算机（Reduced Instruction Set Computer）。

### 复杂指令集——CISC

一开始，计算机指令集只是一条一条比较简单的基本指令，而复杂指令全靠软件编译时通过简单指令组合起来；由于那时的电脑十分昂贵，而且速度很慢，为了提高速度原来越多的复杂指令被加入指令集系统；由于指令集是固定位数的，但是为了融合更多指令集，指令会占用少量地址码（操作码拓展），为了达到操作码扩展的先决条件：减少地址码，设计师们又动足了脑 筋，发明了各种各样的寻址方式，如基址寻址、相对寻址等，用以最大限度的压 缩地址码长度，为操作码留出空间。

就这样，慢慢地，CISC 指令系统就形成了，大量的复杂指令、可变的指令 长度、多种的寻址方式是 CISC 的特点，也是 CISC 的缺点：`因为这些都大大增加了解码的难度，而在现在的高速硬件发展下，复杂指令所带来的速度提升早已不及在解码上浪费点的时间。`

### 简单指令集——RISC

1975 年，IBM 的设计师 John Cocke 研究了当时的 IBM370CISC 系统，发现其中占总指令数仅 20%的简单指令却在程序调用中占了 80%，而占指令数 80%的复杂指令却只有 20%的机会用到。由此，他提出了 RISC 的概念。

RISC 的最大特点是指令长度固定，指令格式种类少，寻址方式种类少，大 多数是简单指令且都能在一个时钟周期内完成，易于设计超标量与流水线，寄存器数量多，大量操作在寄存器之间进行。

### 显式并行指令运算——EPIC

**EPIC:**Explicitly Parallel Instruction Computing 显式并行指令运算是一种指令集架构，由HP和Intel联合开发。EPIC允许处理器根据编译器的调度并行执行指令而不用增加硬件复杂性，该架构由超长指令字架构发展而来，并做了大量改进。

#### 原理

其指令中有3位是用来指示上一条运算指令是不是与下一条指令有相关性，是不是要等上一条指令运行完毕后才能运行下一条，如果没有相关性，则两条指令可同时由不同的CPU节点来处理，这样的方式大大提高了CPU并行运算的效率。

#### 实现

EPIC成为IA-64架构的基础（IA代表Intel Architecture，即英特尔架构，与IA-32对应），这是英特尔与惠普共同开发的纯64位微处理器。英特尔的安腾（Itanium）系统处理器采用了这种架构。

### CPU内核结构

CPU主要由两部分构成：运算器与控制器

#### 运算器

运算器又由四个单元构成：

**算术逻辑运算单元ALU（Arithmetic and Logic Unit）**：主要完成对二进制数据的定点算术运算（加减乘除）、逻辑运算（与或非异或）以及移位操作。在某些 CPU 中还有专门用于处理移位操作的移位器。我们通常所说的“CPU 是 XX 位的”就是指 ALU 所能处理的 数据的位数。

**浮点运算单元 FPU（Floating Point Unit）**：主要负责浮点运算和高精度整数运算。有些 FPU 还具有向量运算的功能， 另外一些则有专门的向量处理单元。

**通用寄存器组**：是一组最快的存储器，用来保存参加运算的操作数和中间结果。

**专用寄存器**：通常是一些状态寄存器，不能通过程序改变，由 CPU 自己控制， 表明某种状态。

#### 控制器

**运算器（CU）**负责运算，而控制器负责CPU的工作控制。控制器由四部分组成：

**指令控制器**：是控制器中相当重要的部分，它要完成取指令、 然后交给执行单元（ALU 或 FPU）来执行，同时还要形成下一条指令的地址。

**时序控制器**：为每条指令按时间顺序提供控制信号。时序控制器包括时钟发生器和倍频定义单元，其中时钟发生器由`石英晶体振荡器`发出非常稳定的脉冲信号，就是 `CPU 的主频`；而`倍频`定义单元则定义了 CPU 主频是存储器频率（总线频率）的几倍。

**总线控制器**：用于控制 CPU 的内外部总线，包括地址总线、数据总线、控制总线等等。

**中断控制器**：用于控制各种各样的`中断请求`，并根据`优先级`的高低对中断请求进行`排队`，逐个交给 CPU 处理。

### CPU的核心设计

CPU 的性能是由什么决定的呢？单纯的一个 ALU 速度在一个 CPU 中并不起决定性作用，因为 ALU 的速度都差不多。而一个 CPU 的性能表现的决定性因素就在于 CPU 内核的设计。

**超标量（Superscalar）**：既然无法大幅提高ALU的速度，有什么替代的方法呢？并行处理的方法又一次产生了强大的作用。所谓的超标量CPU，就是只集成了多个ALU、多个FPU、 多个译码器和多条流水线的CPU，以并行处理的方式来提高性能。

**流水线（Pipeline）**：流水线是现代 RISC 核心的一个重要设计，它极大地提高了性能。对于一条具体的指令执行过程，通常可以分为五个部分：取指令，指令译码， 取操作数，运算（ALU），写结果。其中前三步一般由指令控制器完成，后两步则由运算器完成。当指令控制器工作是运算器基本上在休息，而当运算器在工作时指令控制器却在休息，造成了相当大的资源浪费。解决方法很容易想到，当指令控制器完成 了第一条指令的前三步后，直接开始第二条指令的操作，运算单元也是。流水线系统最大限度地利用了 CPU 资源，使每个部件在每个时钟周期都工作， 大大提高了效率。但是，流水线有两个非常大的问题：相关和转移。

在一个流水线系统中，如果第二条指令需要用到第一条指令的结果，这种情况叫做相关。当第二条指令需要等待第一条指令的结果，而造成流水线等待的现象叫流水线堵塞，而流水线的阻塞现象还是不能完全避免的，尤其是当相关指令非常多的时候。

如果第一条指令是一个条件转移指令，那么系统就会不清楚下面应该执行那一条指令？这时就必须等第一条指令的判断结果出来才能执行第二条指令。条件转移所造成的流水线停顿甚至比相关还要严重的多。所以，现在采用分支预测技术来处理转移问题。虽然我们的程序中充满着分支，而且哪一条分支都是有可能的，但大多数情况下总是选择某一分支。。比如一个循环的末尾是一个分支，除了最后一次我们需要跳出循环外，其 他的时候我们总是选择继续循环这条分支。根据这些原理，分支预测技术可以在 没有得到结果之前预测下一条指令是什么，并执行它。现在的分支预测技术能够 达到 90%以上的正确率，但是，一旦预测错误，CPU 仍然不得不清理整条流水线 并回到分支点。这将损失大量的时钟周期。所以，进一步提高分支预测的准确率 也是正在研究的一个课题。

越是长的流水线，相关和转移两大问题也越严重，所以，流水线并不是越长 越好，超标量也不是越多越好，找到一个速度与效率的平衡点才是最重要的。

### CPU的外核

**解码器（Decode Unit）**

这是 x86CPU 才有的东西，它的作用是把长度不定的 x86 指令转换为长度固 定的类似于 RISC 的指令，并交给 RISC 内核。解码分为硬件解码和微解码，对于 简单的 x86 指令只要硬件解码即可，速度较快，而遇到复杂的 x86 指令则需要进 行微解码，并把它分成若干条简单指令，速度较慢且很复杂。好在这些复杂指令 很少会用到。

Athlon 也好，PIII 也好，老式的 CISC 的 x86 指令集严重制约了他们的性能表现。

**一级缓存和二级缓存（Cache）**

一级缓存（L1 Cache）和二级缓存（L2 Cache）是为了缓解较快的 CPU 与较慢的存储器之间的矛盾而产生的，以及缓存通常集成在 CPU 内核， 而二级缓存则是以 OnDie 或 OnBoard 的方式以较快于存储器的速度运行。对于一些大数据交换量的工作，CPU 的 Cache 显得尤为重要。

一级缓存可分为一级指令缓存和一级数据缓存。一级指令缓存用于暂时存储并向CPU递送各类运算指令；一级数据缓存用于暂时存储并向CPU递送运算所需数据，这就是一级缓存的作用。二级缓存就是一级缓存的缓冲器：一级缓存制造成本很高因此它的容量有限，二级缓存的作用就是存储那些CPU处理时需要用到、一级缓存又无法存储的数据。

### CPU接口

> CPU接口类型决定了主板的选型，目前服务器CPU接口大多为Socket 771、Socket 775、LGA 2011、LGA 1150；

### CPU封装

所谓“封装技术”是一种将集成电路用绝缘的塑料或陶瓷材料打包的技术。以CPU为例，实际看到的体积和外观并不是真正的CPU内核的大小和面貌，而是CPU内核等元件经过封装后的产品

封装技术封装对于芯片来说是必须的，也是至关重要的。因为芯片必须与外界隔离，以防止空气中的杂质对芯片电路的腐蚀而造成电气性能下降。另一方面，封装后的芯片也更便于安装和运输。由于封装技术的好坏还直接影响到芯片自身性能的发挥和与之连接的PCB（印制电路板）的设计和制造，因此它是至关重要的。

1、`BGA封装（ball grid array）`

球形触点陈列，表面贴装型封装之一。在印刷基板的背面按陈列方式制作出球形凸点用以 代替引脚，在印 刷基板的正面装配 LSI 芯片，然后用模压树脂或灌封方法进行密封。也 称为凸 点陈列载体（PAC）。引脚可超过200，是多引脚LSI 用的一种封装。 封装本体也可做得比 QFP（四侧引脚扁平封装）小。例如，引脚中心距为1．5mm 的360引脚 BGA 仅为31mm 见方；而引脚中心距为0．5mm 的304 引脚 QFP 为40mm 见方。而且 BGA不 用担 心 QFP 那样的引脚变形问题。

该封装是美国Motorola 公司开发的，首先在便携式电话等设备中被采用，今后在 美国有 可 能在个人计算机中普及。最初，BGA的引脚（凸点）中心距为 1．5mm，引脚数为225。现在 也有 一些 LSI 厂家正在开发500 引脚的BGA。 BGA 的问题是回流焊后的外观检查。现在尚不清楚是否有效的外观检查方 法。有的认为 ，由于焊接的中心距较大，连接可以看作是稳定的，只能通过功能检查来处理。 美国 Motorola 公司把用模压树脂密封的封装称为 OMPAC，而把灌封方法密封的封装称为 GPAC（见 OMPAC 和 GPAC）。

![img](https://pic1.zhimg.com/80/v2-2fd5ef99dea2724472ab8e9a1e33fa28_1440w.webp)

2、BQFP 封装 （quad flat packagewith bumper）

带缓冲垫的四侧引脚扁平封装。QFP 封装之一，在封装本体的四个角设置突起（缓冲垫） 以 防止在运送过程 中引脚发生弯曲变形。美国半导体厂家主要在微处理器和 ASIC 等电路中采用 此封装。引脚中心距0．635mm， 引脚数从84 到196 左右（见 QFP）。

![img](https://pic4.zhimg.com/80/v2-93052bea3b3b20ee0e385466be1e7483_1440w.webp)

3、碰焊 PGA 封装 （butt joint pin grid array）

表面贴装型 PGA 的别称（见表面贴装型 PGA）。

4、C－（ceramic） 封装

表示陶瓷封装的记号。例如，CDIP 表示的是陶瓷 DIP。是在实际中经常使用的记号。

![img](https://pic3.zhimg.com/80/v2-1ff1933f8fd3373f911ea7ba4b739d3a_1440w.webp)

5、Cerdip 封装

用玻璃密封的陶瓷双列直插式封装，用于 ECL RAM，DSP（数字信号处理器）等电路。带有玻璃窗口的Cerdip

用于紫外线擦除型EPROM 以及内部带有 EPROM 的微机电路等。引脚中 心 距2．54mm，引脚数从8 到42。在日本，此封装表示为 DIP－G（G 即玻璃密封的意思）。

![img](https://pic3.zhimg.com/80/v2-df692a119977e8f1b0389bcbbadacec2_1440w.webp)

6、Cerquad 封装

表面贴装型封装之一，即用下密封的陶瓷 QFP，用于封装 DSP 等的逻辑LSI 电路。带有窗 口的 Cerquad用 于封装EPROM 电路。散热性比塑料 QFP 好，在自然空冷条件下可容许1． 5～ 2W 的功率。但封装成本比塑料QFP 高3～5 倍。引脚中心距有1．27mm、0．8mm、0．65mm、 0．5mm、 0．4mm等多种规格。引脚数从32 到368。

带引脚的陶瓷芯片载体，表面贴装型封装之一，引脚从封装的四个侧面引出，呈丁字形。 带有窗口的用于 封装紫外线擦除型 EPROM 以及带有 EPROM 的微机电路等。此封装也称为 QFJ、QFJ－G（见 QFJ）。

![img](https://pic4.zhimg.com/80/v2-d4ea570c10466a5b9db7e8a5aeaed5c7_1440w.webp)

7、CLCC 封装 （ceramic leadedchip carrier）

带引脚的陶瓷芯片载体，表面贴装型封装之一，引脚从封装的四个侧面引出，呈丁字形。带有窗口的用于封装紫外线擦除型 EPROM 以及带有 EPROM 的微机电路等。此封装也称为 QFJ、QFJ－G（见 QFJ）。

![img](https://pic3.zhimg.com/80/v2-7a825f07ab7a2cc68a98261b8d64c5ba_1440w.webp)

8、COB 封装 （chip on board）

板上芯片封装，是裸芯片贴装技术之一，半导体芯片交接贴装在印刷线路板上，芯片与基板的电气连接用引线缝合方法实现，芯片与基板的电气连接用引线缝合方法实现，并用树脂覆 盖以确保可＊性。虽然 COB 是最简单的裸芯片贴装技术，但它的封装密度远不如 TAB 和倒片 焊技术。

![img](https://pic2.zhimg.com/80/v2-b67445fb230979be0bc2f35176cfd94d_1440w.webp)

9、DFP（dual flat package）

双侧引脚扁平封装。是SOP 的别称（见 SOP）。以前曾有此称法，现在已基本上不用。

![img](https://pic1.zhimg.com/80/v2-c23da2af4eb9235598462e32f6578e24_1440w.webp)

10、DIC（dual in－line ceramic package）

陶瓷 DIP（含玻璃密封）的别称（见 DIP）．

![img](https://pic1.zhimg.com/80/v2-7adcd6f3e4d7935f490cdb3d2f121b68_1440w.webp)

11、DIL（dual in－line）

DIP 的别称（见 DIP）。欧洲半导体厂家多用此名称。

![img](https://pic2.zhimg.com/80/v2-c9d4676251cb6abfbf17932b0b9d233d_1440w.webp)

12、DIP（dual in－line package） 双列直插式封装

插装型封装之一，引脚从封装两侧引出，封装材料有塑料和陶瓷两种。 DIP 是最普及的插装型封装，应用范围包括标准逻辑 IC，存贮器 LSI，微机电路等。

引脚中心距2．54mm，引脚数从6 到64。封装宽度通常为15．2mm。有的把宽度为7．52mm 和10．16mm 的封 装分别称为 skinny DIP 和 slim DIP（窄体型 DIP）。但多数情况下并不加区分，只简单地统称为 DIP。另外，用低熔点玻璃密封的陶瓷 DIP 也称为 cerdip（见cerdip）。

![img](https://pic2.zhimg.com/80/v2-c9d4676251cb6abfbf17932b0b9d233d_1440w.webp)

13、DSO（dual small out－lint）

双侧引脚小外形封装。SOP的别称（见 SOP）。部分半导体厂家采用此名称。

![img](https://pic1.zhimg.com/80/v2-85dff28546cd3d337c16ed62952df6a4_1440w.webp)

14、DICP（dual tape carrier package）

双侧引脚带载封装。TCP（带载封装）之一。引脚制作在绝缘带上并从封装两侧引出。由于利用的是 TAB（自 动带载焊接）技术，封装外形非常薄。常用于液晶显示驱动 LSI，但多数为定制品。另外，0．5mm 厚的存储器 LSI簿形封装正处于开发阶段。在日本，按照 EIAJ（日本电子机械工业）会标准规定，将 DICP 命名为DTP。

![img](https://pic1.zhimg.com/80/v2-a87bc2afc204137c316224f28bd374e4_1440w.webp)

15、DIP（dual tape carrier package）

同上。日本电子机械工业会标准对 DTCP 的命名（见 DTCP）。

![img](https://pic3.zhimg.com/80/v2-c130fbbeaa88ab06865e2033b2eeaa92_1440w.webp)

16、FP（flat package）

扁平封装。表面贴装型封装之一。QFP 或 SOP（见 QFP 和 SOP）的别称。部分半导体厂家采用此名称。

![img](https://pic2.zhimg.com/80/v2-dab37f8bd1cbf1e510ae272a305b113d_1440w.webp)

17、Flip－chip

倒焊芯片。裸芯片封装技术之一，在 LSI 芯片的电极区制作好金属凸点，然后把金属凸点与印刷基板上 的电极区进行压焊连接。封装的占有面积基本上与芯片尺寸相同。是所有封装技术中体积最小、最薄的一种。

但如果基板的热膨胀系数与LSI 芯片不同，就会在接合处产生反应，从而影响连接的可靠性。因此必须用树脂来加固 LSI 芯片，并使用热膨胀系数基本相同的基板材料。其中SiS 756北桥芯片采用最新的Flip－chip封装，全面支持AMD Athlon 64／FX中央处理器。支持PCI Express X16接口，提供显卡最高8GB／s双向传输带宽。支持最高HyperTransport Technology，最高2000MT／s MHz的传输带 宽。内建矽统科技独家AdvancedHyperStreaming Technology，MuTIOL 1G Technology。

![img](https://pic3.zhimg.com/80/v2-cee04ff94a39f9ca9ea484e5319dab52_1440w.webp)

18、FQFP（fine pitch quad flat package）

小引脚中心距 QFP。通常指引脚中心距小于0．65mm 的 QFP（见 QFP）。部分导导体厂家采用此名称。塑料四边引出扁平封装 PQFP（Plastic Quad Flat Package）PQFP 的封装形式最为普遍。其芯片引脚之间距离很小，引脚很细，很多大规模或超大集成电路都采用这种封装形式，引脚数量一般都在100个以上。Intel 系列 CPU 中80286、80386和某些486主板芯片采用这种封装形式。

此种封装形式的芯片必须采用 SMT 技术（表面安装设备）将芯片与电路板焊接起来。采用 SMT 技术安装的芯片 不必在电路板上打孔，一般在电路板表面上有设计好的相应引脚的焊点。将芯片各脚对准相应的焊点，即可实现与主板的焊接。用这种方法焊上去的芯片，如果不用专用工具是很难拆卸下来的。SMT 技术也被广泛的使用在芯 片焊接领域，此后很多高级的封装技术都需要使用 SMT 焊接。

以下是一颗 AMD 的 QFP 封装的286处理器芯片。0．5mm焊区中心距，208根 I／O 引脚，外形尺寸28×28mm， 芯片尺寸10×10mm，则芯片面积／封装面积＝10×10／28×28＝1：7．8，由此可见 QFP 比 DIP 的封装尺寸大大减小了。

![img](https://pic2.zhimg.com/80/v2-180f787229d518619cf11d3a8ca2dbcd_1440w.webp)

19、CPAC（globetop pad array carrier）

美国 Motorola 公司对 BGA 的别称（见 BGA）。

![img](https://pic2.zhimg.com/80/v2-849513ee52e525f00e5d7d646321b4a1_1440w.webp)

20、CQFP 軍用晶片陶瓷平版封裝 （CeramicQuad Flat－pack Package）

右邊這顆晶片為一種軍用晶片封裝（CQFP），這是封裝還沒被放入晶體以前的樣子。這種封裝在軍用品以及航太工 業用晶片才有機會見到。晶片槽旁邊有厚厚的黃金隔層（有高起來，照片上不明顯）用來防止輻射及其他干擾。 外圍有螺絲孔可以將晶片牢牢固定在主機板上。而最有趣的就是四周的鍍金針腳，這種設計可以大大減少晶片封裝的厚度並提供極佳的散熱。

![img](https://pic2.zhimg.com/80/v2-ddb05ce8ecde20f27f35c32964d5bec9_1440w.webp)

21、H－（with heat sink）

表示带散热器的标记。例如，HSOP 表示带散热器的 SOP。

22、Pin Grid Array（Surface Mount Type）

表面贴装型 PGA。通常 PGA 为插装型封装，引脚长约3．4mm。表面贴装型 PGA 在封装的 底面有陈列状的引脚，其长度从1．5mm 到2．0mm。贴装采用与印刷基板碰焊的方法，因而也称 为碰焊 PGA。因为引脚中心距只有1．27mm，比插装型 PGA 小一半，所以封装本体可制作得不 怎么大，而引脚数比插装型多（250～528），是大规模逻辑 LSI用的封装。封装的基材有多层陶瓷基板和玻璃环氧树脂印刷基数。以多层陶瓷基材制作封装已经实用化。

![img](https://pic3.zhimg.com/80/v2-05aa007864850e96c4646178e73e777a_1440w.webp)

PGA 封装 威刚迷你 DDR333本内存

23、JLCC 封装（J－leaded chip carrier）

J 形引脚芯片载体。指带窗口 CLCC 和带窗口的陶瓷 QFJ 的别称（见 CLCC 和 QFJ）。部分半导体厂家 采用的名称。

24、LCC 封装（Leadless chip carrier）

无引脚芯片载体。指陶瓷基板的四个侧面只有电极接触而无引脚的表面贴装型封装。是高速和高频 IC 用 封装，也称为陶瓷 QFN 或QFN－C（见 QFN）。

25、`LGA封装（land grid array）`

触点陈列封装。即在底面制作有阵列状态坦电极触点的封装。装配时插入插座即可。现已实用的有227 触 点（1.27mm 中心距）和447 触点（2．54mm 中心距）的陶瓷 LGA，应用于高速逻辑 LSI 电路。

LGA 与 QFP 相比，能够以比较小的封装容纳更多的输入输出引脚。另外，由于引线的阻抗小，对于高速 LSI 是很适用的。但由于插座制作复杂，成本高，现在基本上不怎么使用。预计今后对其需求会有所增加。

![img](https://pic4.zhimg.com/80/v2-786ccae4d57a40eacd9eb67c82e26eb7_1440w.webp)

AMD 的2．66GHz 双核心的 Opteron F 的 Santa Rosa 平台

![img](https://pic1.zhimg.com/80/v2-e308762ab47b53f63f0cb45815632c20_1440w.webp)

这种封装方式的特点就是触点都在CPU的PCB上，而整个CPU的背部就像网格一样覆盖在CPU背部，而为了能够让主板与CPU连通，主板则承担了提供针脚的工作。所以你会看到只要是LGA封装的CPU，针脚必然都在主板上，而且LGA的封装由于针脚设计的问题，相对来说比较脆弱，而主板针脚损坏了，就极有可能意味着整个主板的损坏了。

26、LOC 封装（lead onchip）

LSI 封装技术之一，引线框架的前端处于芯片上方的一种结构，芯片的中心附近制作 有凸焊点，用引线缝合进行电气连接。与原来把引线框架布置在芯片侧面附近的结构相比，在相同大小的封装中容纳的芯片达1mm 左右宽度。

27、LQFP 封装（low profile quadflat package）

薄型 QFP。指封装本体厚度为1．4mm 的 QFP，是日本电子机械工业会根据制定的新 QFP外形规格所用的名称。

28、L－QUAD封装

陶瓷 QFP 之一。封装基板用氮化铝，基导热率比氧化铝高7～8 倍，具有较好的散热性。 封装的框架用氧化铝，芯片用灌封法密封，从而抑制了成本。是为逻辑 LSI 开发的一种封装，在自然空冷条件下可容许 W3的功率。现已开发出了208 引脚（0．5mm 中心距）和160 引脚（0．65mm 中心距）的 LSI 逻辑用封装，并于1993 年10月开始投入批量生产。

29、MCM封装

多芯片组件。将多块半导体裸芯片组装在一块布线基板上的一种封装。

根据基板材料可分为MCM－L，MCM－C 和MCM－D 三大类。

MCM－L 是使用通常的玻璃环氧树脂多层印刷基板的组件。布线密度不怎么高，成本较低。

MCM－C 是用厚膜技术形成多层布线，以陶瓷（氧化铝或玻璃陶瓷）作为基板的组件，与使用多层陶瓷基板的厚膜混合IC 类似。两者无明显差别。布线密度高于MCM－L。

MCM－D 是用薄膜技术形成多层布线，以陶瓷（氧化铝或氮化铝）或Si、Al 作为基板的组件。布线密谋在三种组件中是最高的，但成本也高。

30、MFP 封装（ mini flatpackage）

小形扁平封装。塑料SOP 或 SSOP 的别称（见 SOP 和 SSOP）。部分半导体厂家采用的名称。

![img](https://pic4.zhimg.com/80/v2-e85103478b9dca23859be099f480e80b_1440w.webp)

31、MQFP 封装 （metric quad flatpackage）

按照 JEDEC（美国联合电子设备委员会）标准对 QFP 进行的一种分类。指引脚中心距为0．65mm、本体厚度 为3．8mm～2．0mm的标准 QFP（见 QFP）。

32、MQUAD 封装 （metal quad）

美国 Olin 公司开发的一种 QFP 封装。基板与封盖均采用铝材，用粘合剂密封。在自然空冷条件下可 容许2．5W～2．8W 的功率。日本新光电气工业公司于1993 年获得特许开始生产。

33、MSP 封装 （mini squarepackage）

QFI 的别称（见 QFI），在开发初期多称为 MSP。QFI是日本电子机械工业会规定的名称。

34、OPMAC 封装 （over molded padarray carrier）

模压树脂密封凸点陈列载体。美国 Motorola 公司对模压树脂密封 BGA 采用的名称（见 BGA）。

![img](https://pic1.zhimg.com/80/v2-18d6b9567b13a7676e179daa654b6788_1440w.webp)

35、P－（plastic） 封装

表示塑料封装的记号。如PDIP 表示塑料 DIP。

![img](https://pic3.zhimg.com/80/v2-69b46bf6df42ba73d54478287fdf56aa_1440w.webp)

36、PAC 封装 （pad arraycarrier）

凸点陈列载体，BGA 的别称（见 BGA）。

![img](https://pic1.zhimg.com/80/v2-5a6182ccc05a8caaa11742b0eb522f60_1440w.webp)

37、PCLP（printed circuit board leadless package）

印刷电路板无引线封装。日本富士通公司对塑料 QFN（塑料 LCC）采用的名称（见 QFN）。引脚中心距有0．55mm 和0．4mm两种规格。目前正处于开发阶段。

![img](https://pic3.zhimg.com/80/v2-02dedb35110ae74b81ac7b81b04c3a86_1440w.webp)

38、PFPF（plastic flat package）

塑料扁平封装。塑料QFP 的别称（见 QFP）。部分 LSI 厂家采用的名称。

39、`PGA（pin grid array）`

陈列引脚封装。插装型封装之一，其底面的垂直引脚呈陈列状排列。封装基材基本上都采用多层陶瓷基板。在未专门表示出材料名称的情况下，多数为陶瓷 PGA，用于高速大规模逻辑LSI 电路。成本较高。引脚中心 距通常为2．54mm，引脚数从64 到447 左右。了为降低成本，封装基材可用玻璃环氧树脂印刷基板代替。也有64～256 引脚的塑料 PGA。另外，还有一种引脚中心距为1．27mm 的短引脚表面贴装型 PGA（碰焊 PGA）。（见表面贴装型 PGA）。

![img](https://pic3.zhimg.com/80/v2-3102c30bdf5221157eecddf65d15bb9a_1440w.webp)

40、Piggy Back

驮载封装。指配有插座的陶瓷封装，形关与 DIP、QFP、QFN 相似。在开发带有微机的设备时用于评价程序确认操作。例如，将 EPROM 插入插座进行调试。这种封装基本上都是定制品，市场上不怎么流通。

![img](https://pic4.zhimg.com/80/v2-bf91dc2957efaa529d2229f2c923531b_1440w.webp)

### CPU同构与异构

 多核出现前，商业化处理器都致力于单核处理器的发展，其性能已经发挥到极致，仅仅提高单核芯片的速度会产生过多热量且无法带来相应性能改善，但CPU性能需求大于CPU发展速度。尽管增加流水线提高频率，但缓存增加和漏电流控制不力造成功率大幅增加，性能反而不如之前低频率的CPU。功率增加，散热问题也严重了，风冷已经不能解决问题了。

  那么新技术必须出现-多核处理器。早在1996年就有第一款多核CPU原型Hydra。2001年IBM推出第一个商用多核处理器POWER4,2005年Intal和AMD多核处理器大规模应用。

  多核处理器越来越流行，无论在服务器、桌面、上网本、平板、手机还是医疗设备、国防、航天等方面。

#### 概念

  从硬件的角度来看，多核设计分为两类。如果所有的核心或CPU具有相同的构架，那么定义为**同构多核（homogeneous）**；如果架构不同，那么称为**异构（heterogeneous）多核**。从应用来看，`同构多核处理器中大多数由通用处理器核构成，每个核可以独立运行，类似单核处理器`。而``异构多核处理器往往同时继承了通用处理器、DSP、FPGA、媒体处理器、网络处理器等`。每个内核针对不同的需求设定的，从而提高应用的计算性能或实时性能。

#### 多核微处理器的运行模式

##### AMP（非对称多进程）

AMP-多个核心相对独立的运行不同的任务，每个核心可能运行不同的操作系统或裸机程序，或者不同版本的操作系统。但是有一个主要核心，用来控制整个系统以及其它从核心。具有主从模式。举个例子，比如一个主要核心控制用户界面UI，从核心控制数据采集以及输出。还有POS机，一个负责UI，一个负责交易。也就是两者负责不同的任务。每个核心有自己的内存空间（同时会有共享的内存空间），另外两者之间还有一定的通信机制。从硬件上来说，这种多处理模式可能是同构的，也可能是异构的，但大多情况是异构多处理器。如MCU+DSP，MCU+FPGA等。同构的当然也有。比如Xilinx就提供了案例，Sun公司的Solari4.1.3系统也支持AMP模式（从主从角度来看，而不是多个操作系统）。Mars Board也可以运行AMP模式。

##### SMP（对称多进程）

SMP-对称多处理，这个是目前用的最多的，一个OS同等的管理各个内核，为各个内核分配工作负载。目前，大多数的系统都支持SMP模式，如Linux，Vxworks，windows。这种模式就是简单提高运行性能。比如PC机上双核、四核运行windows，linux等。所有的核心共享内存。另外，这种模式的通常都是同构多核处理器，因为异构的结构不同，实现比较复杂。

##### BMP（受约束多进程）

BMP-边界多处理，和SMP类似，也是一个OS管理所有内核，但是不同的是，BMP中，开发者可以指定将某个任务仅在某个指定内核上执行。

### 其他CPU

#### ASIC

ASIC（Application Specific Integrated Circuit）专用集成电路，是指应特定用户要求和特定电子系统的需要而设计、制造的集成电路。ASIC在批量生产时与通用集成电路相比具有体积更小、功耗更低、可靠性提高、性能提高、保密性增强、成本降低等优点。
ASIC和FPGA相比，ASIC是专用集成电路，一旦设计完成后集成电路即固定。而FPGA是在阵列内集成大量数字电路基本门电路和存储器，开发人员可以通过烧写FPGA配置来定义电路，并且这种烧写是可更换的。

ASIC适合需求量大，对芯片定制要求较高的场景，比如某些车载专用芯片、矿机芯片。而ASIC因为低耗电、高性能也广受关注，谷歌早在2017年5月就推出数据中心领域专用架构芯片，与GPU相比耗电量降低60%，芯片面积下降40%，能更好的满足其庞大的AI算力要求。

#### FGPA

FPGA（Field Programmable Gate Array）现场可编程门阵列，是作为专用集成电路（ASIC）领域中的一种半定制电路而出现的，既解决了定制电路的不足，又克服了原有可编程器件门电路数有限的缺点。
FPGA是由大量小型处理单元组成的阵列，其中包含多达数百万个可编程的1位自适应逻辑模块（每个模块都可以像一个位的ALU一样工作），多达数万个可配置的存储块以及成千上万个数学引擎，称为数字信号处理（DSP）块，支持可变精度浮点和定点运算。所有这些资源都是通过可根据需要激活的可编程导线网格连接的。FPGA不采用指令和软件，而是软硬件合一的器件。对FPGA进行编程要使用硬件描述语言，硬件描述语言描述的逻辑可以直接被编译为晶体管电路的组合。所以FPGA实际上直接用晶体管电路实现用户的算法，没有通过指令系统的翻译。FPGA可以理解为可编程的数字逻辑电路集成芯片，在“创作”一块FPGA其实是在描绘一个数字逻辑电路。

FPGA适合定制化场景较浓，但需求量又不大的场景，类似数通设备。目前随着数据中心、公有云的发展，FPGA也在这些新兴领域大显身手，微软的数据中心、百度大脑、华为云的FPGA加速等都已经用上了FPGA：用 FPGA 加速适合它的计算任务，其他任务仍然在CPU上完成，让FPGA和CPU协同工作。

## 内存

### DDR

DDR=Double Data Rate双倍速率同步动态随机存储器。严格的说DDR应该叫DDR SDRAM，人们习惯称为DDR，其中 SDRAM 即同步动态随机存取存储器。而DDR SDRAM是双倍速率同步动态随机存储器的意思。DDR内存是在SDRAM内存基础上发展而来的，仍然沿用SDRAM生产体系，因此对于内存厂商而言，只需对制造普通SDRAM的设备稍加改进，即可实现DDR内存的生产，可有效的降低成本。

**同步动态随机存取内存（简称SDRAM）**是有一个同步接口的动态随机存取内存（DRAM）。通常DRAM是有一个异步接口的，这样它可以随时响应控制输入的变化。而**SDRAM有一个同步接口，在响应控制输入前会等待一个时钟信号，这样就能和计算机的系统总线同步。**时钟被用来驱动一个有限状态机，对进入的指令进行管线操作。**这使得SDRAM与没有同步接口的异步DRAM相比，可以有一个更复杂的操作模式。**

SDRAM在计算机中被广泛使用，SDRAM从发展到现在已经历了五代，分别是：第一代SDR SDRAM，第二代DDR SDRAM，第三代DDR2 SDRAM，第四代DDR3 SDRAM，第五代，DDR4 SDRAM。

**第一代SDRAM采用单端时钟信号,第二代、第三代与第四代由于工作频率比较快，所以采用可降低干扰的差分时钟信号作为同步时钟。**SDR SDRAM的时钟频率就是数据存储的频率，第一代内存用时钟频率命名，如pc100，pc133则表明时钟信号为100或133MHz，数据读写速率也为100或133MHz。

**之后的第二，三，四代DDR（Double Data Rate）内存则采用数据读写速率作为命名标准，并且在前面加上表示其DDR代数的符号，PC-即DDR，PC2=DDR2，PC3=DDR3。如PC2700是DDR333，其工作频率是333/2=166MHz，2700表示带宽为2.7G。DDR的读写频率从DDR200到DDR400，DDR2从DDR2-400到DDR2-800，DDR3从DDR3-800到DDR3-1600。**

很多人将SDRAM错误的理解为第一代也就是 SDR SDRAM，并且作为名词解释，皆属误导。SDR不等于SDRAM。

**Pin**:模组或芯片与外部电路连接用的金属引脚，而模组的pin就是常说的**“金手指”**。

**SIMM**：Single In-line Memory Module,单列内存模组。**内存模组就是我们常说的内存条**，所谓单列是指模组电路板与主板插槽的接口只有一列引脚（虽然两侧都有金手指）。

**DIMM**：Double In-line Memory Module，双列内存模组。是我们常见的模组类型，所谓双列是指模组电路板与主板插槽的接口有两列引脚，模组电路板两侧的金手指对应一列引脚。

**RIMM**：registered DIMM，带寄存器的双线内存模块，这种内存槽只能插DDR或Rambus内存。

**SO-DIMM**:笔记本常用的内存模组。

**工作电压：**

SDR：3.3V、DDR：2.5V、DDR2：1.8V、DDR3：1.5V、DDR4：1.2V

SDR SDRAM内存条的金手指通常是168线，而DDR SDRAM内存条的金手指通常是184线的。几代产品金手指的缺口数及缺口位置也不同有效防止反插与错插，SDR SDRAM有两个缺口，DDR只有一个缺口。

### ECC内存

在电子数字的世界里，所有的信息都是以简单的“0”与“1”表示；不过当数据在电子元件间进行传递时，是有可能发生数据“误传”的情形，也就是说原来该是0的比特数据，却被误植为1的比特数据，而产生错误。其可能发生的原因相当多，包括电子噪声、元件硬件上的问题，或是传输接口不稳等，都可能造成如此的结果。

这种状况若发生在存储器中，所带来的灾难则是可大可小。比如在游戏中，你可能对画面上突然显色不正常的小方块不以为意，但此时若不是在游戏中，而是正在进行硬盘重组的工作，相信结果将令你花容失色，惊叫起来。也正因为如此，在存储器中便发展出**ECC与Parity Check等的检错方式**，希望能降低数据传输的错误。

**Parity工作原理**

早先所使用的存储器数据检错方式是Parity Check，其是以每8比特增加1比特的方式进行检错。因此**若是具备Parity的存储器，其数据宽度将比非parity的存储器为大**。不过若以Parity的检错方式看，其多出的奇偶位事实上只用于分辨奇数或偶数个比特数。以表格1为例（假设工作时采用奇数形式），当所有的比特数据在加上奇偶位后，总位数应该是奇数，因此当数据从存储器被读出时，若不为奇数值，系统便能得知在数据中必有某一位发生错误，而达到检错的目的。不过很可惜的是，**这种方式仅能得知是某一位发生错误，并无法确定是哪一个位置发生错误。**

另外奇偶位检错还有一个大问题。在表格1中，读者可以发现11101101与01101111相加后总的位数相同，差别仅在第1个与第7个位置上比特值不同。若此时两者分别代表存在存储器中的数据，与读取存储器后传出的数据时，就发生了前面所说的错误情况。不过此时却无法从Parity校验中得知数据发生错误，因此Parity事实上是**无法运用在双数位的检错上**！

**ECC工作原理**

**ECC则是另一种更为进步的存储器数据检错机制**。其工作的方式与Parity不同，并不是采用单一比特的方式来进行检错，而是采用数据块（block）概念与复杂的演算方法来修正数据。因此**不仅能检测多位比特错误，还能进行修正单一比特的错误**。以168针的DIMM存储器模块来说，若以64bits为一数据块单位，便需要8bits的容量来作为ECC之用（32bits则需7bits），因此总数据宽度便与168针的Parity存储器相同。

而由于如此，多数主机板可以利用具有Parity功能的168针存储器来执行ECC；不过也有少数的主机板，只能使用经过特殊设计的ECC存储器执行此功能，是读者需要注意的地方。不过若要能确实执行ECC功能，除了所购买的存储器规格要支持外，主机板芯片组（如Intel 440BX、430HX等）也需要支持，且制造厂商也必须在主机板上设计开启此项功能，才能毕尽全功。由于具ECC的存储器在设计上比较复杂一些，因此价格自然也就比较高了。

### Chipkill 内存

#### **简介**

Chipkill内存最初是由20年前的IBM大型机发展过来的，Chipkill是为美国航空航天局(NASA)的"探路者"探测器赴火星探险而研制的。它是IBM公司为了弥补目前服务器内存中ECC技术的不足而开发的，是一种新的ECC内存保护技术。

**对比旧ECC内存技术的优点**，ECC内存技术虽然可以同时检测和纠正单一比特错误，但如果同时检测出两个以上比特的数据错误，则无能为力。但基于Intel处理器架构的服务器的CPU性能以几何级的倍数提高，而硬盘驱动器的性能同期只提高了5倍，因此为了保证正常运行，服务器需要大量的内存来临时保存从CPU上读取的数据。这样大的数据访问量就导致单一内存芯片在每次访问时通常要提供4(32位)或8(64位)字节以上的数据。一次性读取这么多数据，出现多位数据错误的可能性会大大提高，而ECC又不能纠正双比特以上的错误，这样就很可能造成全部比特数据的丢失，系统就会很快崩溃。IBM的Chipkill技术是利用内存的子结构方法来解决这一难题的。

#### **设计原理**

Chipkill内存子系统的设计原理是这样的:在Chipkill技术支持下，单一内存芯片无论数据宽度是多少，只有一个给定的ECC识别码，它的影响最多为一比特。举个例子来说明，如果使用4比特宽的SDRAM，4比特中的每一位的奇偶性将分别组成不同的ECC识别码，每个ECC单元可单独用一个数据位来保存，也就是说这些识别码分别保存在不同的内存空间中。因此，即使整个内存芯片出了故障，每个ECC单元也将最多出现一比特坏数据。出现这种情况完全可以通过ECC进行逻辑修复，从而保证了内存子系统的容错性，保证了服务器在出现故障时，有强大的自我恢复能力。Chipkill内存控制器所提供的存储保护在概念上和具有校验功能的磁盘阵列类似。在写数据的时候，**把数据写到多个DIMM内存芯片上。这样，每个DIMM所起的作用和存储阵列相同。如果其中任何一个芯片失效了，它只影响到一个数据字节的某一比特，因为其他比特存储在另外的芯片上。出现错误后，内存控制器能够从失效的芯片重新构造"失去"的数据，使得服务器可以继续正常工作**。采用这种Chipkill内存技术的内存可以同时检查并修复4个错误数据位，进一步提高了服务器的实用性。

#### **发展**

目前支持Chipkill内存技术的不仅是IBM服务器，许多国内的服务器，如宝德公司的64位新至强机架式服务器PR2520，该公司还有许多其他服务器也支持这一内存技术，如PT4050R和PR2520等)、方正公司的方正圆明MT500等也开始支持这一技术。当然实际应用这一技术的服务器厂商远不止这些，可以说Chipkill得到了广泛应用，主要是在中、低端服务器中。

新型的第三代Chipkill内存技术已经集成到了IBM的x架构的芯片组中，不必另外定制。最初IBM公司在主机系统中开发了这一技术，到现在已具有20多年的历史。这种新的功能既可以检测，又可以纠正多比特内存错误，可进一步提高服务器的实用性。同时服务器中只需采用便宜的、工业标准的ECC存储器，而不必另外购买专门的内存，所以IBM的Chipkill内存技术的应用非常广。

------

### Registered ECC

REG ECC内存上面的芯片一般比ECC多出2-3个，主要是**PLL (Phase Locked Loop)和Register IC**。它们的具体用处如下：**PLL**(Phase Locked Loop) 琐相环集成电路芯片，内存条底部较小IC，比Register IC小，一般只有一个，起到调整时钟信号，保证内存条之间的信号同步的作用。**Register IC**内存条底部较小的集成电路芯片(2-3片),起提高驱动能力的作用。服务器产品需要支持大容量的内存，单靠主板无法驱动如此大容量的内存，而使用带Register的内存条，通过Register IC提高驱动能力，使服务器可支持高达32GB的内存。

RECC 和 ECC 的区别：

1、要求不一样

REG ECC，必须用服务器主板才能支持；ECC，普通主板可以用，但是ECC纠错功能不起作用。

2、硬件不一样

REG ECC 带有一个寄存器。ECC，则没有寄存器。

3、价格不一样

ECC内存比普通内存贵10%-20%，REG ECC内存比普通内存贵一倍左右。

4、读取方式不一样

ECC和 是控制器直接读内存颗粒，REG ECC 是控制器读寄存器，寄存器读颗粒。

5、延迟不一样

REG ECC 因为比 ECC 多了一道程序，所以稍有延迟。

![img](https://pic3.zhimg.com/80/v2-0a5f9fec29992a7be49e0416ff0f3a2a_1440w.webp)

**扩展资料：**

REG ECC 缩写是 RECC。REG 是英语 Register 的缩写，意思为寄存器的意思，其功能是通过它来集成更多的内存颗粒达到扩大内存容量的目的。

ECC 是英文 Error Checking &Correcting 的缩写，翻译为错误检查和纠正，可以理解为内存条的数据纠错功能，这也是为什么服务器可以连续运行几个月甚至几年不死机的原因。

------

### 常见的内存类型

常见的内存类型有这几种：**Non-ECC内存，Un-buffered-ECC内存和Register**内存。

其中**Non-ECC内存**为最常见的消费级内存，这种内存不带缓存，也没有寄存器，延迟更小，通常用于台式机。

**Un-buffered-ECC内存**为带错误检查和纠正的无缓冲内存，这种内存也俗称为纯ECC内存，它可以提供单一错误纠正和检测，常用于NAS，小型服务器以及可以支持的平台上。Intel平台的E3，四代以上的i3以及AMD平台的锐龙系列其实也是可以支持这种内存的。

**Register内存**则为带缓存，寄存器和ECC功能的内存，**这种内存也分为RDIMM，LRDIMM两种**，这两种内存都有用于优化时钟、命令和控制信号的寄存器，通常用于大型服务器上。

**RDIMM为带存储器的DIMM**，通过添加8位的奇偶校验信号来实现错误纠正，**LRDIMM则为低负载双列的DIMM**，通过放置数据在缓冲区来优化数据信号。

而且Register内存的区块组织和普通内存的不一样，例如Register内存就有1Rx4，1Rx8，2Rx4，2Rx8，4Rx4，8Rx4等规格，不同规格的内存颗粒数量是不一样的，例如1Rx4的有18个内存颗粒，2Rx4的有36个内存颗粒，而且兼容性对于不同主板也是不一样的，例如有些主板可以支持1Rx8的，但不一定能支持2Rx4的。

**Register内存的支持条件则需要满足这几个，其中一个没有满足的话就可能会用不了。**

1.CPU支持，例如支持Reg内存的X79和X99主板使用i7就不能支持，要使用E5才能支持Reg内存。

2.芯片组支持，这个是老平台的条件，因为老平台的内存控制器还没有集成到CPU里面，例如X58芯片组就不一定能支持Reg内存，而服务器的5500，5520芯片组就可以支持，但X79平台开始因为内存控制器集成到CPU里面了，所以就和芯片组的关系不大了。

3.主板BIOS支持，主板BIOS如果不支持Reg内存的话可能也无法启动。

4.主板内存到CPU的电路布局支持，因为Reg内存和普通内存的走线是不一样的，所以主板电路也是需要支持的。

最后总结一下，**Non-ECC内存、Un-buffered-ECC都属于无缓冲内存**，无缓冲内存其中的内存控制器和RAM芯片之间不存在硬件寄存器。**Register内存称为寄存内存，也称为缓冲内存**，也就是DRAM模块和内存控制器中间有一个寄存器。

缓冲内存比无缓冲内存更稳定，也就是Reg内存相比普通内存和纯ECC内存来说是更稳定的。

------

**ECC与RECC内存之间的区别**

我们知道，在选购服务器内存的时候，相比台式机普通内存型号，通常带有ECC或者RECC的标注，不少用户不知道ECC和RECC到底是什么，那么内存ECC是什么意思？下面宏旺半导体分享一下服务器内存ECC和RECC之间能否兼容及区别科普。

一谈到服务器内存，大家都一致强调要买ECC内存，认为ECC内存速度快，其实是一种错误地认识，ECC内存成功之处并不是因为它速度快，而是因为它有特殊的纠错能力，使服务器保持稳定。ECC本身并不是一种内存型号，也不是一种内存专用技术，它是一种广泛应用于各种领域的计算机指令中，是一种指令纠错技术。

![img](https://pic1.zhimg.com/80/v2-9677bdfd1b0d06f6ef8d8024ff381b30_1440w.webp)

ECC 校验是一种内存纠错原理，它是比较先进的内存错误检查和更正的手段。ECC内存即纠错内存，简单的说，其具有发现错误，纠正错误的功能，一般多应用在高档台式电脑/服务器及图形工作站上，这将使整个电脑系统在工作时更趋于安全稳定。

![img](https://pic4.zhimg.com/80/v2-1bc1a29f45220ac73c957454b07e0793_1440w.webp)

内存是一种电子器件，在其工作过程中难免会出现错误，而对于稳定性要求高的用户来说，内存错误可能会引起致命性的问题。内存错误根据其原因还可分为硬错误和软错误，硬件错误是由于硬件的损害或缺陷造成的，因此数据总是不正确，此类错误是无法纠正的；软错误是随机出现的，例如在内存附近突然出现电子干扰等因素都可能造成内存软错误的发生，ECC技术就是为了纠正内存软错误。

**ECC** **和RECC内存条之间的区别**

从功能上，ECC有特殊的纠错能力，使服务器保持稳定。ECC是一种校验（奇偶效验），RECC是REG ECC的简写，RECC的R表示register，寄存器，也就是说，RECC就是在ECC的基础上加了个寄存器，大大提高服务器内存工作效率，这个是服务器内存，必须用服务器主板才能支持，一般的主板点不亮。

![img](https://pic1.zhimg.com/80/v2-35c9d566479e5d3a6429735bb4b960f8_1440w.webp)

**服务器内存ECC和RECC之间能否兼容?**

**两者通常不兼容的**，需要看主板支持，RDIMM可以用RECC和普通内存，UDIMM只能ECC，当然也有同时有RDIMM和UDIMM的，那就可以混合了。

其中REG就是Register，寄存器，你可以理解为一个订书机，它可以把内存芯片（纸张）集成的更多，简单点就是扩容用的，通过它来集成更多的内存颗粒达到扩大内存容量的目的。

至于ECC就是Error Checking &Correcting的缩写，简单的说就是内存条的数据纠错功能，这就是为什么服务器可以连续运行几个月甚至几年不死机的原因。当然RECC内存价格是ECC的一倍，而ECC内存比普通内存贵10%-20%。宏旺半导体旗下嵌入式存储产品均使用了ECC纠错技术，保障存储器的稳定性。

**内存DIMM ECC什么意思 ？**

DIMM的意思是“双列直插式存储模块”，ECC是一种能够实现“错误检查和纠正”的技术，ECC内存就是应用了这种技术的内存，一般多应用在服务器及图形工作站上，可使整个电脑系统在工作时更安全稳定。内存**DIMM ECC合在一起就是采用双列直插式存储模块并能进行错误检查和纠正的内存**！

## 网卡

### 什么是网卡？

网卡的名称有很多，比如网络接口控制器、网络接口卡、以太网卡、局域网卡、网络适配器或网络适配器卡等。尽管名称各异，它们都是指能使计算机和服务器等网络设备相互连接的电路板。内嵌式网卡在大多数计算机和一些网络服务器中都很常见，除此之外，还可以将服务器网卡等插入设备的扩展槽中。网卡就像一个转换器，将数据转换为数字信号，通过使用电缆线或服务器网络上的无线路由器进行通信。

网卡作为TCP/IP层的接口，可以在物理层传输信号，在网络层传输数据包。无论位于哪个层，它都充当计算机或服务器和数据网络之间的中间媒介。当用户发送一个web页面请求时，网卡从用户设备中获取数据，并将其发送到网络服务器，然后接收所需的数据展示给用户。

### 网卡的构成

网卡一般由一个控制器、一个boot ROM槽、一／多个网卡端口、一个主板接口、LED指示灯、一个支架和一些其他电子元件组成，每个部件都有其独特的功能：

**控制器：**控制器就像一个微型CPU，用来处理接收到的数据。控制器作为网络适配器的核心部分，直接决定着网络适配器的性能。

**boot ROM槽：**网卡上的这个槽能启用boot ROM功能，boot ROM可使无磁盘工作站连接到网络，在提高安全性的同时降低硬件成本。

**网卡端口：**通常情况下，该端口直接与以太网线或光模块连接，产生和接收网线或光纤跳线上的电信号。

**总线接口：**该接口位于电路板的一侧，通过插入扩展槽连接网卡和计算机或服务器。

**LED指示灯：**指示灯用于帮助用户识别网卡的工作状态，确认网络是否连接，数据是否传输。

**支架：**市面上有两种类型的支架，一个是全长12cm的全高支架，另一个是长8cm的半高支架。这个支架可以帮助用户将网卡固定在计算机或服务器的扩展槽中。

### 网卡的种类

根据主机接口、传输速度、应用领域等不同，网卡可分为以下几个不同的类型。

### 基于网络连接方式分类

基于网卡访问网络的方式，可将网卡分为有线网卡和无线网卡。顾名思义，有线网卡通常需要用一根跳线（如以太网跳线和光纤跳线）将一个节点连接到网络；无线网卡通常带有一个小天线，利用无线电波与接入点进行通信，从而接入无线网络。

### 基于总线接口类型分类

**ISA总线网卡：**ISA总线发布于1981年，是IBM标准兼容的总线结构。由于9Mbps的网卡速度较慢，ISA总线接口逐渐被淘汰，现在市场上很少见。

**PCI总线网卡：**PCI发布于19世纪90年代，替代了以前的ISA标准。它的固定宽度为32位（数据传输速率为133MB/s）和64位（数据传输速率为266MB/s）。这种类型的网卡最初用于服务器，后来逐渐应用于电脑。如今大多数电脑没有扩展卡，而是采用嵌入式网卡。因此，PCI总线网卡已被其他总线接口取代，如PCI- X或USB接口。

**PCI-X网卡：**PCI- X是一种增强的PCI总线技术。它支持64位运行，最高可达1064MB/s。多数情况下PCI- X的插槽与PCI网卡是向后兼容的。

**PCIe网卡：**PCIe是一种最新的标准，在计算机和服务器主板上很流行。PCIe网卡现在有五个版本，分别支持不同的速度。

![img](https://pic1.zhimg.com/80/v2-7e277d9c42f1b37d9e08924777106dc0_1440w.webp)

**USB网卡：**USB总线是一种外部总线标准。它有三个版本，具有不同的传输速率，可以与各种设备一起工作。

### 基于接口类型的分类

根据连接线材的不同，市场上有四种类型的网卡端口。

RJ-45端口用于连接双绞线（如Cat5和Cat6）， AUI端口用于粗同轴电缆（如AUI电缆），BNC端口用于细同轴电缆（如BNC电缆），光端口用于模块（如10G/25G光模块）。

### 基于传输速度的分类

基于不同的速度，网卡有10Mbps，100Mbps， 10/100Mbps自适应卡，1000Mbps、10G、25G甚至更高速度的网卡。10Mbps、100Mbps和10/100Mbps自适应网卡适用于小型局域网、家庭或办公室。1000Mbps网卡可为快速以太网提供更高的带宽。10Gb/25Gb网卡以及更高速度的网卡则受到大企业与数据中心的欢迎。

### 基于应用领域的分类

**电脑网卡：**现在大多数新计算机的主板都内置了网卡，因此不需要单独的局域网卡。它通常具有10/100Mbps和1Gbps的速度，并允许一台PC与其他PC或网络通信。

**服务器网卡：**服务器网卡的主要功能是管理和处理网络流量。与普通计算机网卡相比，服务器网卡要求更高的数据传输速度，如10G、25G、40G甚至100G。另外，服务器网卡的CPU占用率很低，因为它有一个特殊的网络控制器，可以减轻CPU的负担。为满足用户对服务器网卡速度的不同需求，飞速(FS)推出了10G PCIe网卡和25G/40G网卡，这些网卡使用英特尔控制器，支持多核处理器与服务器和网络虚拟化的优化

### 服务器网卡

网卡有哪些分类呢？现在小编就带着大家来了解一下。

![一分钟带你了解服务器网卡](https://img.ithome.com/newsuploadfiles/2022/10/fc852baa-f666-4cd1-b867-f5ef9e0301d9.png?x-bce-process=image/format,f_auto)

服务器专用网卡 VS 普通网卡

相对于服务器专用网卡来说，普通网卡指应用在普通 PC、工作站、消费级电子产品中的网卡对可靠性、安全性等要求不高，而服务器与普通 PC 工作站的不同之处是服务器一直处于工作中，且要求长时间稳定运行，这就要求服务器网卡具有以下特点：

- 数据传输速度快

服务器时刻处于数据计算、交换过程中，普通网 10Mbps、 100Mbps 的数据已不满足大数据流量网络，当前服务器常用的网卡速率为 10Gbps、25Gbps 等。

- CPU 占用率低

服务器的 CPU 是不停工作的，处理着大量的数据。如果一台服务器的 CPU 大部分时间都在为网卡提供数据响应，势必会影响到对其他任务的处理速度。服务器网卡有自带的控制芯片，可以处理一些 CPU 任务，从而减少 CPU 的计算开销。

- 安全性能高

如果服务器的网卡出现故障，则服务器将无法接收，发送数据，相当于宕机，所以高可靠性是是服务器网卡的必备特性。服务器网卡基本上 都具有容错功能，如 Intel 的 AFT（网卡出错冗余），ALB（网卡负载均衡）等技术。

### **服务器的网卡**

- NIC：Network interface Card

特指以太网卡，支持 TCP / IP 协议，应用于以太网络中

- CNA：Converged Network Adapter

融合网卡，本质上是以太网卡，但支持 FCoE 功能（FC over Ethernet）

- HBA：Host Bus Adapter、

特指 FC 网卡，支持 FC 协议，连接存储或光纤交换机

- HCA：Host Channel Adapter

特指 Infiniband 网卡，即 IB 卡。应用于高带宽，低时延的高性能计算机中

### 网卡接口

网卡的物理接口主要有两种：电口和光口

- 电口：即普通的 RJ45 接口，例如：连接网线

![一分钟带你了解服务器网卡](https://img.ithome.com/newsuploadfiles/2022/10/b335af08-99b0-4599-8fc6-1f21ce2f2184.png?x-bce-process=image/format,f_auto)

- 光口：用于连接光模块

根据接口封装形工，可以分为 SFP+、SFP28、QSFP+

SFP+：支持 GE / 10GE 速率

SFP28：支持 GE / 10GE / 25GE 速率

QSFP+：支持 40GE / 100GE 速率

![一分钟带你了解服务器网卡](https://img.ithome.com/newsuploadfiles/2022/10/031b15ea-8fcf-4c09-a631-34c3eced5ad3.png?x-bce-process=image/format,f_auto)

### 网卡厂商

网卡有哪些厂商？后起之秀------nvidia

![img](https://img.ithome.com/newsuploadfiles/2022/10/7624770c-6fbe-4188-a6f4-ffa0669491c2.png?x-bce-process=image/format,f_auto)

## 显卡

**什么是显卡？**

显卡（Video card，Graphics card）全称[显示接口卡](https://www.zhihu.com/search?q=显示接口卡&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A517317050})，又称显示适配器，是计算机最基本配置、最重要的配件之一。就像电脑联网需要[网卡](https://www.zhihu.com/search?q=网卡&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A517317050})，主机里的数据要显示在屏幕上就需要显卡。因此，显卡是电脑进行[数模信号](https://www.zhihu.com/search?q=数模信号&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A517317050})转换的设备，承担输出显示图形的任务。具体来说，**显卡接在[电脑主板](https://www.zhihu.com/search?q=电脑主板&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A517317050})上，它将电脑的数字信号转换成[模拟信号](https://www.zhihu.com/search?q=模拟信号&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A517317050})让显示器显示出来**。

原始的显卡一般都是集成在主板上，只完成最基本的信号输出工作，并不用来处理数据。随着显卡的迅速发展，就出现了GPU的概念，显卡也分为独立显卡和集成显卡。

**什么是GPU？**

GPU这个概念是由Nvidia公司于1999年提出的。GPU是显卡上的一块芯片，就像CPU是主板上的一块芯片。那么1999年之前显卡上就没有GPU吗？当然有，只不过那时候没有人给它命名，也没有引起人们足够的重视，发展比较慢。

自Nvidia提出GPU这个概念后，GPU就进入了快速发展时期。简单来说，其经过了以下几个阶段的发展：

1）**仅用于图形渲染**，此功能是GPU的初衷，这一点从它的名字就可以看出：Graphic Processing Unit，图形处理单元；

2）后来人们发现，GPU这么一个强大的器件只用于图形处理太浪费了，它应该用来做更多的工作，例如[浮点运算](https://www.zhihu.com/search?q=浮点运算&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A517317050})。怎么做呢？直接把浮点运算交给GPU是做不到的，因为它只能用于图形处理（那个时候）。最容易想到的，是把浮点运算做一些处理，包装成图形渲染任务，然后交给GPU来做。这就是**GPGPU（General Purpose GPU）**的概念。不过这样做有一个缺点，就是你必须有一定的[图形学](https://www.zhihu.com/search?q=图形学&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A517317050})知识，否则你不知道如何包装。

3）于是，为了让不懂图形学知识的人也能体验到GPU运算的强大，Nvidia公司又提出了CUDA的概念。

**什么是CUDA？**

CUDA(Compute Unified Device Architecture)，通用[并行计算架构](https://www.zhihu.com/search?q=并行计算架构&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A517317050})，是一种运算平台。它包含CUDA指令集架构以及GPU内部的[并行计算引擎](https://www.zhihu.com/search?q=并行计算引擎&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A517317050})。你只要使用一种类似于C语言的**CUDA C语言**，就可以开发CUDA程序，从而可以更加方便的利用GPU强大的计算能力，而不是像以前那样先将计算任务包装成图形渲染任务，再交由GPU处理。

**注意，并不是所有GPU都支持CUDA。**

**CPU和GPU的关系**

在没有GPU之前，基本上所有的任务都是交给CPU来做的。有GPU之后，二者就进行了分工，**CPU负责逻辑性强的事物处理和[串行计算](https://www.zhihu.com/search?q=串行计算&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A517317050})，GPU则专注于执行高度线程化的并行处理任务（大规模计算任务）**。为什么这么分工？这是由二者的硬件构成决定的。

 可以看出，**CPU是“主（host）”而GPU是“从（device）”**，GPU无论发展得多快，都只能是替CPU分担工作，而不是取代CPU。

**独立显卡和集成显卡的区别。**

所谓集成，是指显卡集成在主板上，不能随意更换。而独立显卡是作为一个独立的器件插在主板的AGP接口上的，可以随时更换升级。

另外，集成显卡使用物理内存，而独立显卡有自己的显存。一般而言，同期推出的独立显卡的性能和速度要比集成显卡好、快。

值得一提的是，集成显卡和独立显卡都是有GPU的。

**结束语：**

CUDA只是一种并行计算架构，相关的概念还有OpenCL、OpenMP等。

##  Raid卡与HBA卡

**阵列卡**就是英语中的**raid卡**，**直通卡**就是**HBA卡**。

HBA卡有两种模式，IT模式和IR模式，IR模式的直通卡不是硬阵列卡！别拿IR模式的直通卡说是硬阵列卡！这么说是非常不准确的了。

![img](https://pic2.zhimg.com/80/v2-a53032faaac1f1400c06ec6601d6ba61_1440w.webp)

lsi9207是it模式，lsi9217是ir模式，可以互刷

![img](https://pic3.zhimg.com/80/v2-cc5b773ec49011ab688cb25bf26af46a_1440w.webp)

lsi9272刷成lsi9207，最小的静音直通卡

HBA卡就是一个通道卡，它的作用是让计算机能够对硬盘进行直接管理和使用，一般都是针对sas硬盘，可以看成是sas控制器，而sas是兼容SATA的，所以SATA硬盘也可以用。有点类似南桥的SATA控制器。但是HBA卡的HBA芯片也是包含有通用CPU的。

HBA分为IT模式和IR模式，IT模式下所连接的磁盘对系统是透明的，由系统直接识别和管理；而IR模式下磁盘由HBA控制器控制然后模拟磁盘给系统使用，虽然类似阵列卡（和南桥的raid模式也有些相似），而且raid0，1的时候系统资源占用比南桥组阵列或者系统组建的软阵列要少，但是这依然不能称为硬阵列卡。IR模式下的HBA卡可以组建raid0，raid1甚至raid5，但是raid5的写入性能极差，甚至还不如单个硬盘。我一直觉得IR模式的HBA卡就是废物，基本找不到什么用途会特别需要这种卡，raid0不安全，raid1性能差，难道就用来做raid1安装操作系统吗？后来想想应该是厂商拿来骗钱的。做raid的ROC芯片的残次品丢了多可惜，屏蔽一下作为HBA卡，然后再赋予它“raid”功能，还能raid5，然后又能卖好多钱。

IT直通卡的个人玩家的主要用途就是NAS，现在的各种NAS系统为了从系统层面管理硬盘都只能用直通卡，无法使用硬阵列卡。即使是IR模式的HBA卡也不好用，所以都是用的IT模式的直通卡多，当然，使用虚拟机做NAS系统的除外，虚拟机是可以使用硬阵列卡的。

![img](https://pic1.zhimg.com/80/v2-884a717599757f836e146829e2993c00_1440w.webp)

电池版lsi9271阵列卡

![img](https://pic4.zhimg.com/80/v2-ada41eaf92e47df52b8886f836c6d22b_1440w.webp)

CV超级电容版lsi9271阵列卡

硬阵列卡可以看做是一个微型计算机系统，阵列卡通过一个ROC（raid-on-chip）芯片来完成对存储设备的管理，并按需模拟磁盘给计算机使用，硬盘本身对操作系统不透明，由阵列卡管理。ROC芯片中主要包括有通用CPU，一般是mips，powerpc或者arm架构，大多都采用双核架构，用来通用计算；还有xor引擎，专门用来加速raid5，raid6，对抗raid5和6的写惩罚提高写入速度；还有内存控制器为XOR引擎和CPU提供ram内存作为缓存使用，特别是用来对抗raid5和6的写惩罚使用。硬阵列卡做的raid5，6，50，60才是真正具有强大的读写性能和很好的容灾能力的硬磁盘阵列。

硬阵列卡和直通卡最简单的识别方式就是看有没有没有内存颗粒作为阵列卡缓存。没有的的就是HBA卡或者说直通卡，而有内存颗粒作为阵列卡缓存的大多是硬阵列卡。硬阵列卡做raid5或者raid6速度特别是写入速度是有保障的。而IR模式的直通卡，即使能做raid5，也是聋子的耳朵-摆设，毫无实用价值

## 存储

说到“存储”，大家会想到什么？

是这个？



![img](https://pic1.zhimg.com/80/v2-971165faa1fc0ff9e174731465ed147c_1440w.webp)



还是这个？



![img](https://pic3.zhimg.com/80/v2-4abda6dc5e88c3867a7017c86a1e20e6_1440w.webp)

又或者是这个？

![img](https://pic4.zhimg.com/80/v2-4d5ca51b5866bf1dafc73b548102dd3f_1440w.webp)

没错，我们现在处于信息时代，每天都在和电脑、手、平板机打交道。我们的工作和生活，已经完全离不开视频、音乐、图片、文本、表格这样的数据文件。



![img](https://pic1.zhimg.com/80/v2-86b75c52de8ca41ee499a1718d5f1634_1440w.webp)



而所有这些数据文件，都需要通过电子设备进行保存，这就是数据存储，简称存储。

### **存储的基本载体——硬盘**

对于普通用户来说，最常见的存储设备，就是硬盘。我们知道，计算机的三大核心硬件，分别是CPU（中央处理器）、内存（Memory）和硬盘（Hard Disk）。CPU负责运算，硬盘负责存储。而内存，是CPU和硬盘之间的桥梁。用于暂时存放CPU中的运算数据。所以内存相当于一个垃圾中转站，用于暂时存放需要清理的生活垃圾。我们可以用一张图片来说明：

![img](https://pic4.zhimg.com/80/v2-c6027a9dfd28dbaaa97307f05110bbd7_1440w.webp)

CPU、内存、硬盘

绝大部分的台式机、服务器、手机，都是内置存储系统。也就是说，它们的硬盘安装在设备内部，相当于正常人的大脑，是生长在我们体内的。

常用的硬盘专用接口如下：

![img](https://pic4.zhimg.com/80/v2-80a569d880b588ed96c8168a8ad4ea57_1440w.webp)

手机等数码设备的“大脑”，则是做成了很小的存储芯片，直接焊在主板上。

![img](https://pic1.zhimg.com/80/v2-82ca70ef113b3777cabd0d79a4ee5144_1440w.webp)

我们再来简单看看硬盘的内部结构。

![img](https://pic1.zhimg.com/80/v2-e3346154de8d43ac20cc659df59c8ed0_1440w.webp)

目前主流的硬盘类型有两种，分别是传统机械硬盘和SSD固态硬盘。

有好多朋友想知道传统机械硬盘和SSD盘的区别，可以参考小编以前发的一篇文章哦。这里就以大家比较熟悉的机械硬盘为例进行介绍。

硬盘之所以叫硬盘，是因为它的核心部分是一块或多块由坚硬金属材料制成的盘片。盘片上面涂抹了磁性介质，两面都可以记录信息。在盘面上读/写数据的，是磁头。

![img](https://pic2.zhimg.com/80/v2-2c93c6277f64b21136e46a36d492fd85_1440w.webp)

硬盘，也叫磁盘（有点像唱片机）

![img](https://pic2.zhimg.com/80/v2-948da039852677c2c0cd9b9a46d4f5e9_1440w.webp)

下图显示的是一个盘面，这真的不是蚊香：

盘面中一圈圈灰色同心圆为一条条磁道。从圆心向外画直线，可以将磁道划分为若干个弧段，每个弧段被称之为一个扇区（Sector，图中绿色部分）。扇区是磁盘的最小组成单元。大家应该看出来了，越靠圆心，扇区越短。那么，是不是越往外，扇区越长，存储的数据越多呢？不一定。老式的硬盘，不管靠内还是靠外，每个扇区的大小是一样的，都是512字节。这种硬盘用柱面-磁头-扇区号（CHS，Cylinder-Head-Sector）组成的编号进行寻址。而现在主流的硬盘，扇区密度是一致的，也就是说，越靠外侧，扇区数越多。每个扇区的大小是4K字节，用一个逻辑块编号寻址（LBA，Logical Block Addressing）。以扇区为基础，一个或多个连续的扇区组成一个块，叫做物理块。所以，硬盘往往又叫块设备（Block Device）。

### **什么是逻辑卷？什么是文件系统？**

为了方便管理，我们可以将硬盘这样的物理块设备，分割成多个逻辑块设备。或者，我们也可以将多个物理块设备，组合成一个容量更大的逻辑块设备。

底层的相关技术和工具，包括RAID（大家可能比较熟悉）、JBOD、卷管理系统（Volume Manager）。Windows的卷管理系统，就是它自带的磁盘管理工具。而Linux的，是大名鼎鼎的LVM（Logical Volume Manager，逻辑卷管理）。我们先说说Windows的。在Windows中，磁盘分为基本磁盘和动态磁盘。默认情况下，用户用的都是基本磁盘。一个基本磁盘可以划分为多个分区，分区类别包括主分区、扩展分区和逻辑分区。

![img](https://pic2.zhimg.com/80/v2-7f24a280c0742bda659ebc4a7d2476a1_1440w.webp)

主分区是硬盘的启动分区，我们常说的“C盘”就是硬盘上的主分区。MBR分区表可以划分出4个主分区。如果使用GPT分区，可以管理128个主分区。除去主分区以外，硬盘剩下的容量就被认定为扩展分区。扩展分区不能直接使用。扩展分区可以分成一个或若干个逻辑分区，也就是我们的“D盘”、“E盘”等。

![img](https://pic2.zhimg.com/80/v2-916c05ad1210a579232e5103d2d3e97d_1440w.webp)

动态磁盘是基本磁盘的升级模式。在动态磁盘中，分区叫做卷。卷的出现，就是为了便于对多硬盘进行管理。简单来说，动态磁盘可以将不同硬盘分到一个卷。假如你手中有160G和250G硬盘各一块，如果想划分90G和320G的分区，就可以借助动态磁盘来完成。动态磁盘里面的卷，又分为简单卷、跨区卷、带区卷、镜像卷、RAID-5卷。限于篇幅，就不做具体介绍了。基本磁盘里的分区，现在也被微软改叫为卷。再来看看Linux的LVM工具。其实LVM和动态磁盘的思路差不多的，也是把物理空间变成逻辑空间。首先，物理存储介质进行初始化，变成物理卷（PV，physical volume）。然后，一个或多个物理卷组成一个卷组（VG，Volume Group）。创建卷组之后，再创建逻辑卷（LV，logical volume）。整个过程，如下图所示：

![img](https://pic1.zhimg.com/80/v2-66b09252d3e915237e98a3a7ec859e18_1440w.webp)

#### LVM主要元素的构成

好了，不管是Windows还是Linux，逻辑卷都有了，是不是可以直接使用它们啦？不行，还差一步。那就是文件系统（File System）。文件系统就像仓库管理员。作为用户，你不需要知道仓库里面到底是什么样子，只需要把货物交给他，他会以一个树形结构目录，登记这些货物。你来取的时候，只需要告诉他路径，他就会把货物交给你。

文件系统有很多种类型，常见的有Windows的FAT/FAT32/NTFS（大家应该很熟悉），还有就是Linux的EXT2/EXT3/EXT4/XFS/BtrFS等。Windows系统下，通过对分区（卷）进行文件系统格式化，再分配一个盘符，我们就可以在“我的电脑”里看到可用的磁盘。Linux系统下，我们需要对逻辑卷进行文件系统格式化，然后执行挂载操作，也就能对存储空间进行使用了。

##### **什么是DAS/NAS/SAN**

除了内置存储之外，随着存储容量需求的不断增加，加上维护便利性的需要，计算机系统开始引入了外挂存储。也就是说，大脑不够用了，我们请上了笔记本，俗话说好记性不如烂笔头。外挂存储分为两种，一种是直连式存储（DAS，Direct Attached Storage），还有一种是网络存储（FAS，Fabric Attached Storage）。DAS直连式存储，一般是使用专用线缆（例如SCSI），与存储设备（例如磁盘阵列）进行直连。

![img](https://pic2.zhimg.com/80/v2-d7952539d254ad62438a80cc585cca19_1440w.webp)

虽然数据存储设备看似在外部，但直接挂接在服务器内部总线上，是整个服务器结构的一部分。DAS的缺点是存储设备只能连接到一台主机使用，无法共享，成本较高，且安全性可靠性较低。FAS网络存储，是一种多点连接式的存储。它又分为NAS（Network-attached Storage，网络接入存储）和SAN（Storage Area Network，存储区域网络）。这些概念的名字非常像，大家千万别晕。画个图看得明白一些：

![img](https://pic3.zhimg.com/80/v2-84a629ede6ff265aa2499681ccb265e6_1440w.webp)

NAS与DAS相比，最大的特点是非直连。它可以通过IP网络，实现多台主机与存储设备之间的连接。

![img](https://pic4.zhimg.com/80/v2-17c2f3ca201b1cdaead4de4ccf5154d3_1440w.webp)

NAS大大提高了存储的安全性、共享性和成本。但是I/O（输入输出）渐渐成为性能瓶颈。随着应用服务器的不断增加，网络系统效率会急剧下降。为了解决这个问题，出现了SAN存储方案。SAN是在NAS基础上做的演进。它通过专用光纤通道交换机访问数据，采用ISCSI、FC协议。SAN和NAS的关键区别，就在于文件系统的位置。画个图就明白了：

![img](https://pic1.zhimg.com/80/v2-c7e3fced3ee3e12ea775cfac9bcf28d0_1440w.webp)

可以看出，如果说SAN是一块网络硬盘的话，NAS基本上已经像一台独立的服务器了。NAS拥有文件系统，用户可以通过TCP/IP协议直接访问上面的数据。

现在很多家庭都开始使用小型NAS设备，相当于一个小型服务器。在NAS的模式下，不同的客户端可以使用网络文件系统（Network File System）访问NAS上的文件。常见的网络文件系统有Windows网络的CIFS（也叫SMB）、类Unix系统网络的NFS等。FTP、HTTP其实也算是文件存储的某种特殊实现，它们通过某个URL地址来访问一个文件。

## BMC与IPMI

**BMC（Baseboard Management Controller）与IPMI（Intelligent Platform Management Interface）**，即基板管理控制器与智能型平台管理接口，是服务器的基本核心功能子系统，负责服务器的硬件状态管理、操作系统管理、健康状态管理、功耗管理等核心功能。

**BMC** **是独立于服务器系统之外的小型操作系统**，是一个集成在主板上的芯片，也有产品是通过 PCIE 等形式插在主板上，对外表现形式只是一个标准的 RJ45 网口，拥有独立 IP 的固件系统。服务器集群一般使用 BMC 指令进行大规模无人值守操作，包括服务器的远程管理、监控、安装、重启等。

**IPMI** **是一组交互标准管理规范**，由 Intel、HP、Dell 和 NEC 公司于1998年9月16日共同提出，主要用于服务器系统集群自治，监视服务器的物理健康特征，如温度、电压、风扇工作状态、电源状态等。同时，IPMI 还负责记录各种硬件的信息和日志记录，用于提示用户和后续问题的定位。目前，IPMI 已经为超过 200 多家计算机供应商所支持。

**IPMI 是独立于主机系统 CPU、BIOS/UEFI 和 OS 之外，可独立运行的板上部件，其核心部件即为 BMC。**或者说，BMC 与其他组件如 BIOS/UEFI、CPU 等交互，都是经由 IPMI 来完成。在 IPMI 协助下，用户可以远程对关闭的服务器进行启动、重装、挂载 ISO 镜像等。

![img](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9tbWJpei5xcGljLmNuL21tYml6X3BuZy9hamd5QVVjUllSZWljOXBBazMwOXlubnRxUjlmR3RYeDFNZ04zTkR4dnFBaWFqbWljUkRuQU5XMmJ4TGJJY2xJcXQ2UXA3cHQzME5OaWJzdjJSZmRXWXFWMEEvNjQw?x-oss-process=image/format,png)

## 交换机

简单来说，交换机就是用于实现局域网内计算机的互联。交换机（Switch）意为“开关”是一种用于电（光）信号`转发`的[网络设备](https://baike.baidu.com/item/网络设备/7667828?fromModule=lemma_inlink)。它可以为接入交换机的任意两个[网络节点](https://baike.baidu.com/item/网络节点/9338583?fromModule=lemma_inlink)提供独享的[电信号](https://baike.baidu.com/item/电信号/1594125?fromModule=lemma_inlink)通路。最常见的交换机是[以太网交换机](https://baike.baidu.com/item/以太网交换机/10186103?fromModule=lemma_inlink)。其他常见的还有电话语音交换机、[光纤交换机](https://baike.baidu.com/item/光纤交换机/8396782?fromModule=lemma_inlink)等。

交换是按照通信两端传输信息的需要，用人工或设备[自动完成](https://baike.baidu.com/item/自动完成/22748028?fromModule=lemma_inlink)的方法，把要传输的信息送到符合要求的相应路由上的技术的统称。交换机根据[工作位置](https://baike.baidu.com/item/工作位置/55385239?fromModule=lemma_inlink)的不同，可以分为[广域网](https://baike.baidu.com/item/广域网/422004?fromModule=lemma_inlink)交换机和[局域网交换机](https://baike.baidu.com/item/局域网交换机/8465756?fromModule=lemma_inlink)。广域的交换机就是一种在[通信系统](https://baike.baidu.com/item/通信系统/1975602?fromModule=lemma_inlink)中完成信息交换功能的设备，它应用在[数据链路层](https://baike.baidu.com/item/数据链路层/4329290?fromModule=lemma_inlink)。交换机有多个端口，每个端口都具有[桥接](https://baike.baidu.com/item/桥接?fromModule=lemma_inlink)功能，可以连接一个局域网或一台[高性能服务器](https://baike.baidu.com/item/高性能服务器/55734947?fromModule=lemma_inlink)或工作站。实际上，交换机有时被称为多端口网桥。

[网络交换机](https://baike.baidu.com/item/网络交换机/2105356?fromModule=lemma_inlink)，是一个扩大网络的器材，能为[子网络](https://baike.baidu.com/item/子网络/12720714?fromModule=lemma_inlink)中提供更多的连接端口，以便连接更多的计算机。随着[通信业](https://baike.baidu.com/item/通信业/9231824?fromModule=lemma_inlink)的发展以及[国民经济信息化](https://baike.baidu.com/item/国民经济信息化/10361145?fromModule=lemma_inlink)的推进，网络交换机市场呈稳步上升态势。它具有性价比高、高度灵活、相对简单和易于实现等特点。[以太网](https://baike.baidu.com/item/以太网/99684?fromModule=lemma_inlink)技术已成为当今最重要的一种局域网组网技术，网络交换机也就成为了最普及的交换机。 [1] 

Switch是交换机的英文名称，这个产品是由原集线器的升级换代而来，在外观上看和[集线器](https://baike.baidu.com/item/集线器/214614?fromModule=lemma_inlink)没有很大区别。由于通信两端需要传输信息，而通过设备或者人工来把要传输的信息送到符合要求标准的对应的路由器上的方式，这个技术就是交换机技术。从广义上来分析，在通信系统里对于信息交换功能实现的设备，就是交换机。 [2]

> **交换机工作原理**

1、交换机的作用：

- 连接多个以太网物理段，隔离冲突域
- 对以太网帧进行高速而透明的交换转发
- 自行学习和维护MAC地址信息

交换机工作在二层，可以用来隔离冲突域，在OSI参考模型中，二层的作用是寻址，这边寻址指的是MAC地址，而交换机就是对MAC地址进行转发，在每个交换机中，都有一张MAC地址表，这个表是交换机自动学习的。

所以，总得来说交换机的作用是寻址和转发，这边需要注意的是寻址和转发都是MAC地址，需要跟上周分享的路由器区分开来，路由器寻址寻的是IP地址，而交换机是MAC地址。

2、交换机的特点：

- 主要工作在OSI模型的物理层、数据链路层
- 提供以太网间的透明桥接和交换
- 依据链路层的MAC地址，将以太网数据帧在端口间进行转发

3、交换机MAC地址表转发过程：

MAC地址表初始化：

![img](https://pic1.zhimg.com/80/v2-741cddbc902e9efc8636e6ffc2c055a4_1440w.webp)

交换机刚启动时，MAC地址表中无表项。以上图中的交换机就是刚刚启动的时候的MAC地址表。可以看出并没有任何的表项，当接入PC的时候，交换机开始进行学习MAC地址，见下图：

MAC地址表学习过程（1）

![img](https://pic3.zhimg.com/80/v2-fb0d709603ead2dfb4f3c206823586f6_1440w.webp)

- PCA发出数据帧
- 交换机把PCA的帧中的源地址MAC_A与接收到此帧的端口E1/0/1关联起来
- 交换机把PCA的帧从所有其他端口发送出去（除了接收到帧的端口E1/0/1）

MAC地址表学习过程（2）

![img](https://pic3.zhimg.com/80/v2-fb0d709603ead2dfb4f3c206823586f6_1440w.webp)

PCB、PCC、PCD发出数据帧交换机会把接收到的帧中的源地址与相应的端口关联起来，至此，交换机的MAC地址表学习完成，开始进行数据的转发。

4、交换机对数据帧的转发与过滤

单播帧的转发：

![img](https://pic2.zhimg.com/80/v2-66f93b24fe6f0666959eb629c6613261_1440w.webp)

- PCA发出目的到PCD的单播数据帧
- 交换机根据帧中的目的地址，从相应的端口E1/0/4发送出去
- 交换机不在其他端口上转发此单播数据帧

广播、组播和未知单播帧的转发：

![img](https://pic2.zhimg.com/80/v2-4220b11946b4edcbea586cd9d2bf1509_1440w.webp)

交换机会把广播、组播和未知单播帧从所有其他端口发送出去（除了接收到帧的端口）

> **VLAN基本原理**

1、广播风暴

![img](https://pic4.zhimg.com/80/v2-26ed2a4eb34486f9743c8b96189122b7_1440w.webp)

所谓广播帧就是在二层环境中设备发出的广播帧在广播域中传播，这样会导致广播镇占用网络带宽，降低设备性能。

2、使用三层设备路由器隔离广播域

![img](https://pic2.zhimg.com/80/v2-f15f75e0a6954bf1789e7a80fa67b93d_1440w.webp)

广播帧属于二层并不会跨越三层，所以为了解决广播风暴，可以使用三层设备隔离广播域，减小广播域范围。比如使用路由器来隔离广播域，由于路由器是三层设备，对数据的转发容易形成瓶颈，所以一般我们使用VLAN来隔离广播域。

3、VLAN隔离广播

![img](https://pic3.zhimg.com/80/v2-199c2102bbfaf6b2ee4c2ffd11b840d2_1440w.webp)

二层交换机使用VLAN（虚拟局域网）隔离广播，用来减小广播域范围。这样的话，不同VLAN之间是无法进行通信的，假设PCA发送一个广播帧，只会在VLAN1之间传播并不会传播到VLAN2，这样既限制了广播域的范围，又保证了VLAN2的安全性。

4、VLan优点

![img](https://pic3.zhimg.com/80/v2-f5309f7797636f6203e667bc824be3ea_1440w.webp)

- 有效控制广播域范围
- 增强局域网的安全性
- 灵活构建虚拟工作组

5、VLAN分类（VLAN的划分方法）

基于端口的VLAN：

![img](https://pic4.zhimg.com/80/v2-b880b6fc0f919b1944127c3da8e53dab_1440w.webp)

基于端口的VLAN划分方法是最常用的一种划分方法，就是一个或者几个端口属于一个VLAN，这个端口下面的用户也就属于该 VLAN。假设以上图中，E1/0/1和E1/0/2属于VLAN10，E1/0/3和E1/0/4属于VLAN20，那么PCA和PCB也都都属于 VLAN10，可以互相通信，PCC和PCD属于VLAN20，也可以互相通信。

这种划分方法的优先就是配置比较方便，只要在交换机上将相应的端口加入相应的 VLAN 即可，缺点是对于用户来说如果更改了交换机的端口也就更换了VLAN ID。

基于MAC地址的VLAN：

![img](https://pic3.zhimg.com/80/v2-52d028acc5f174e7034c89203740ed66_1440w.webp)

基于 MAC 地址的 VLAN 就是在划分 VLAN 的时候根据 MAC 地址划分 VLAN，比如将 PCA和 PCB 的 MAC 地址划分在 vlan10中，那么 PCA 和 PCB 就属于 VLAN10，PCC 和 PCD 同理。

这种划分方法的优点是对于用户来说不受地理位置的闲置，不管PCA用户接在哪个接口，都属于VLAN10，缺点是配置较基于端口的划分方法繁琐。

基于协议的VLAN：

![img](https://pic3.zhimg.com/80/v2-e5f20e8a1b87b5efba5ae725b4c25632_1440w.webp)

这种划分方法是指运行不同的协议划分到相同的VLAN中，比如PCA和PCB都运行的是IP协议，属于VLAN10，PCC和PCD同理。

此种划分方法优点依旧是不受物理位置的影响，不管PCA接在交换机的哪个接口，都属于VLAN10。缺点的其实PC真正可以运行的协议并没有很多，有划分vlan数量上的限制。

基于子网的VLAN：

![img](https://pic3.zhimg.com/80/v2-2c92c1497fc3e316a26601be1b61693e_1440w.webp)

这种划分方法是根据子网划分，比如10.0.0.0/24属于VLAN10,20.0.0.0/24属于vlan20；

以上四种划分方法最常用配置最方便是基于端口的VLAN划分方法，后面的实验示例也是以基于端口的划分方法。

6、Vlan技术原理

VLAN标签：

![img](https://pic1.zhimg.com/80/v2-43e6a4b89a41330dbab4defd7525cf64_1440w.webp)

对于交换机来说，是根据VLAN标签来区分不同VLAN的以太网帧的。比如PCA发送一个目的地址为PCB的数据帧，到达交换机，交换机会打上VLAN 10的标签，然后根据vlan表确定从PCB的端口转发出去交给PCB。下面会详细介绍VLAN标签的操作。

802.1Q帧格式：

![img](https://pic1.zhimg.com/80/v2-f52185330afa334b2b1f1a4fd48b3cbc_1440w.webp)

我们知道PC发送的数据并不带VLAN标签，那么VLAN ID的标签是什么时候打上的呢，其实是在数据中进入交换机端口的时候打上的。在标准的以太网帧的源地址SA和类型Type之间打上的Tag标签，此tag标签中含有VLAN ID，VLAN ID的范围为4096，去掉一个默认的vlan 1和vlan4096作为保留vlan，实际可用的vlan ID个数为4094个。

单交换机VLAN标签操作：

![img](https://pic1.zhimg.com/80/v2-14f91c5d664e318659c3f6abc30a7be4_1440w.webp)

上面已经提过PC发送的数据不带VLAN标签，所以实在进入交换机的时候打上vlan标签，既然PC发出的数据不带VLAN标签，那么在出交换机的时候交换机需要对数据帧的VLAN标签进行剥离再转发给相对应的PC。

例如：PC发送一个保标准的以太网帧，源地址为PCA的地址，目的地址为PCC的地址，到达交换的时候端口的时候，交换机会打上VLAN10的标签，然后根据vlan表从PCC所在的端口转发，同时需要将VLAN 10的标签剥离，也就是说此数据帧到达PCC的时候依旧是标准的以太网帧，并不带VLAN标签，PCB和PCD同理。

Access链路类型端口：

![img](https://pic4.zhimg.com/80/v2-1d99855bca1fba4659264b3dfc09d6f3_1440w.webp)

VLAN 有三种链路类型，常用的是 Access 和 trunk 链路类型，下面也是介绍这种链路类型。第一种是 Access 链路类型，此链路类型的特点是指允许缺省的 VLAN 通过，同时仅发送和接收一个 VLAN 的数据帧。

所以 access 链路类型一般适用于连接用户设备，也就是交换机直接接 PC使用 access 链路。

跨交换机VLAN标签操作：

![img](https://pic1.zhimg.com/80/v2-a731e334d72a02d3d7e16c1ee8e4c1e0_1440w.webp)

上面讲过，vlan 标签是在进入交换机的时候打上的，出交换机剥离标签，那么在如上的拓扑中，PCA 发送一个目的地址到PCC的数据帧，到达 SWA，SWA 打上 VLAN10的标签，然后从E1/0/24剥离标签然后转发出去，到达 SWB 打上vlan10的标签，从E1/0/1转发到 PCC，这是正常数据帧的转发，但是上面说过Access链路类型只支持一个数据帧通过，那么入股 PCB 同时再发一个 VLAN20 的数据帧的话就无法进行转发，为此，通过 trunk 链路类型实现。

Trunk 链路类型端口：

![img](https://pic1.zhimg.com/80/v2-73c3545f0ca35028e9e80311b6e0f680_1440w.webp)

Trunk 链路类型的有点久是允许多个 VLAN 通过，可以接收和发送多个 VLAN 的数据帧。同时对于缺省的 VLAN 也就是 PVID 的以太网帧是不带标签的。

所以 trunk 链路类型一般用户交换机之间的连接。

## 路由器

路由器（Router），又称路径器，是工作在**IP层**上，可以连接不同的网络，能够**选择数据传送路径并对数据进行转发**的网络设备，属于第三层转接设备。被连接的两个IP子网在物理上既可能是局域网，也可能是广域网，他们具有不同的IP网络号，不能直接通信，需经过路由器进行转接。多协议的路由器可以连接使用完全不同的网络层、数据链路层和物理协议层的网络。单位内部网络与互联网的连接、不同单位网络之间的连接、单位内部不同子网之间的连接都需要使用到路由器[1][2]。

![img](https://pic4.zhimg.com/v2-b8d3ae12dc1a98ecd2841648e23eb041_b.jpg)

### **工作原理**

**（一）IP地址**

实现网络中通信节点的彼此连接，首先需要给每个节点一个唯一的标识，IP网中的标识就是IP地址，他包括一部分定义网络号以及另一部分定义网络内的主机号。拥有唯一标识之后，需要路由器接收所连接的网络或由路由器传来的数据报，并根据数据报的目的IP地址将报文从正确的接口转发出去。

**（二）控制部分与数据转发部分**

路由器内部包括控制部分和数据转发部分。控制部分的路由协议可以有不同的类型。路由器通过路由协议交换网络的拓扑结构信息，依照拓扑结构动态生成路由表。

![img](https://pic4.zhimg.com/v2-689f0e26ef39283c5ad97243cd504257_b.jpg)

在数据转发部分，转发引擎从输入线路接受IP分组之后，分析并修改分组头，使用转发表查找下一跳，把数据交换到输出线路上，向相应方向转发。转发表是根据路由表生成的，其表项和路由表项有直接对应关系，更适合实现快速查找。转发的主要流程包括线路输入、分组头分析、数据存储、分组头修改和线路输出。[2]

**（三）输入与输出端口**

输入端口是物理链路的连接点，也是数据的接收点。它完成的功能主要包括数据链路层帧的封装和解封装。未来提供QoS支持，输入端口可以根据预先指定的策略对接收的报文进行分类。

输出端口主要完成数据的排队、缓冲管理以及调度输出，同时也要执行数据的封装和支持物理层、链路层协议。[2]

**（四）选路策略与选路机制**

![img](https://pic2.zhimg.com/v2-a820fe3eb8dd12ca50f4a5fdfaff1ff9_b.jpg)

选路策略的实质是确定传输数据的最佳路径，它是通过建立和维护路由表来实现的。添加、删除或更新一条路由，可以采用静态路由或动态路由两种方式。

而选路机制则指的是如何查找路由表，并根据查表的结果把数据转发出去。一般来讲路由器首先搜索匹配主机地址，若无则搜索匹配网络地址，最后搜索默认路由。在查找路由表时，可以使用不同的算法，如哈希算法、radix算法等。[1]

### **主要功能**

**（一）组网方面**



![img](https://pic1.zhimg.com/v2-842855f975abe1e8b843b208988996d8_b.jpg)图片：分组队列调度 图源：董民,周卫东,沈庆国, 路由器原理、操作及应用[M], 北京：国防工业出版社, 2006.06, ISBN号 ：7-118-04484-9

1. 连接广域网，并具备路由选择能力
2. 连接的不同的局域网，为它们之间的通信提供选路功能，实现IP分组的转接。
3. 通过分段改进局域网性能。将一个局域网划分为多个网段，不同网段之间阻隔广播包，避免“广播风暴”。
4. 多协议路由器可以连接使用不同通信协议的网络段，实现不同协议间的转换。

**（二）安全防护功能**

防止非法的信息访问和恶意的网络攻击。一方面是外部网络对内部网络的信息窃取和攻击，另一方面是阻止内部网络某些用户对于外部网络的访问。

**（三）网络管理功能**

对网络流量进行控制，满足不同用户的服务质量要求。

**（四）IP地址共享**

通过在内部地址和外部地址间的转换，使内部用户可以使用有限的外部公开IP地址访问互联网。[2]

### **类型划分**

**（一）按性能档次划分**

![img](https://picx.zhimg.com/v2-a54c68d9dd9419115814305a2e6a5029_b.jpg)

**分为高、中、低档路由器**。通常以路由器吞吐量大小为主要划分标准，并综合其他指标，如分组转发迟延、路由表规模及其收敛速度、组播容量、服务质量保证等指标，进行划分。通常情况下，吞吐量大于40Gb/s的路由器被称为高档路由器；中档路由器的吞吐量在25Gb/s-40Gb/s之间；低于25Gb/s的被认为是低档路由器。[2]

**（二）按结构划分**

1. **模块化结构路由器**可以灵活配置，能适应企业不断增加的业务需求，通常高、中档路由器为模块化结构。
2. **非模块化结构路由器**只能提供固定的端口，低档路由器一般为非模块化结构。[2]

**（三）按功能划分**

1. **骨干级路由器**是实现企业级网络互联的关键设备，其数据吞吐量较大，基本要求是高速度和高可靠性。普遍采用热备份、双电源、双数据通路等传统冗余技术，从而满足其可靠性要求。

![img](https://pic3.zhimg.com/v2-9fabe1b5f4003d6ab81b7103a8d1e266_b.jpg)

2. **企业级路由器**连接许多终端系统，连接对象较多，系统相对简单，且数据流量小。对其的要求是以尽量便宜的方法实现尽可能多的端点互联，同时还要求能够支持不同的服务质量。
3. **接入级路由器**主要应用于连接家庭或ISP内的小型企业客户群体。[2]

**（四）按所处网络位置划分**

1. **边界路由器**处于网络边缘，用于不同网络的连接。主要功能是实现对于用户流量的识别、标记和管理。

![img](https://pic2.zhimg.com/v2-c70efb9f97aac164b8a4c51df1202839_b.jpg)

2. **中间节点路由器**则处于网络的中心，通常用于连接不同网络。由路由器根据标记的分组，起到数据转发的桥梁作用。[2]

**（五）按性能划分**

1. **线速路由器**可以完全按照传输线路速率进行通畅传输，基本上没有间断和延时，高端路由器一般是线速路由器，有很高的端口宽带和数据转发能力，能以线路速率转发数据包。
2. **中、低端路由器**通常是非线速路由器，但一些新的宽带接入路由器时也有线速转发能力。[2]

**（六）其他**

1. **无线网络路由器**

![img](https://pic3.zhimg.com/v2-4b6bc1b36bae967f086cf84f518a1642_b.jpg)

**无线网络路由器**是一种用来连系有线和无线网络的通讯设备，它可以通过无线方式连接终端设备，进而建立计算机网络。有的电信运营商为会提供含有Wi-Fi的路由器，通过简单地设置拨号可以实现宽带的共享。无线方式更易受环境影响，如天气等。其它的无线方式有：红外线、蓝牙、卫星微波等。[3]

**2. 策略路由**

**策略路由**比常规路由灵活，并非基于目标网络进行数据包路由-转发，而是额外定义路由-转发的规则。规则包含策略与操作，共同称为路由图。作用于接口，检查该接口接收到的所有数据包是否符合路由图中的策略，不符合则按常规路由进行处理，符合则按路由图中策略对应的操作进行处理。

**四、发展历程**

1970年代中期至19080年代，多功能的小型计算机充当路由器，ARPAnet称之为接口信息处理器。现代高速路由器是由专门的高性能计算机充当，通过加入额外硬件以便高速执行普通路由功能和特殊路由功能。

![img](https://pic2.zhimg.com/v2-f4d75fe5c5122d8bf3e4aec5a3a9ee03_b.jpg)

**（一）总体发展**

路由器通常被认为是网络速度的瓶颈，近年来对于路由器研究的重点也在提高路由器的处理速度上。20世纪90年代以来，世界上许多公司推出了G比特路由器和T比特路由器，这些路由器的光接口速度远远超过了ATM交换机，未来网络的核心变成了宽带IP网络。

IETF综合各大公司专有的三层交换技术，在1998年推出了性能优越的多协议标签交换MPLS，力图解决三层交换网络流量管理的问题。

**（二）软件体系结构发展**

**1.单一软件结构的尽力发送型路由器。**

指的是提供尽力发送型服务而不能扩展，除非替换整个操作系统。当负载较低时路由器能快速转发分组，但当负载较高时，分组等待的时间较长，甚至可能被丢弃。

**2. 单一软件结构的扩展服务型路由器。**

可以提供扩展服务，但内核仍是运行时不可扩展的单一内核。

**3. 流可配置的扩展服务路由器。**

实现了冗余的扩展服务模块，用户可以配置路由器的工作模式，使路由器把某一类流传递给某个模块。但内核仍是运行时不可扩展的单一内核

**4, 运行时可修改的扩展服务路由器。**

![img](https://pic1.zhimg.com/v2-106b6386ac1667a9c7818b06c14e6c34_b.jpg)

此类包含了第二及第三类型路由器的所有特性。且允许用户在运行时修改路由器的扩展服务模块。由管理员在任意时刻升级，将新模块装入路由器之后，才能够发挥作用。

**5. 自动升级的扩展服务路由器。**

此类包含第四类路由器的全部特性，还可以通过收到包括新的功能请求的消息来触发升级。[2]

**（三）实现技术的发展历程**

1. **通用CPU阶段**

![img](https://pic4.zhimg.com/v2-549bf9c5abd2e31f3b46f42fdb19943b_b.jpg)

采用通用CPU作为硬件转发平台，具有高度灵活性的优势。在20世纪80年代末——90年代路由器早期发展的十几年间，CPU为核心转发硬件的路由器占据了几乎全部的市场。高端与低端路由器之间的差别仅在于采用的路由器性能和数量上的不同。

**2. NP阶段**

NP很好地解决了网络业务提供丰富性和性能矛盾的问题，可以保证在一定性能的情况下通过软件升级提供各种各样的业务。同时对业务做了相应的微码优化，对特定业务的处理能力也有了很大的提升。NP以其灵活的可编程特性可以实现良好的对多业务特性的支持，被认为适合骨干网的汇聚层路由器采用。

**3. FPGA阶段**

![img](https://pic4.zhimg.com/v2-b6a05a145956f4b1120bdeb1b17460e3_b.jpg)

是可以反复编程、擦除、使用以及在外围电路不动的情况下用不同软件可以实现不同功能的一种门阵列芯片，可以一定程度上灵活地扩展业务处理类型，但FPGA由于技术的限制，无法很好地同时处理多种协议。一般仅应用于少量简单协议的扩展。

**4. ASIC阶段**

对于特定的业务，ASIC能够提供极高的转发性能和较低的成本，但由于其固定特性，无法解决路由器对于多业务支持的需求。20世纪末一些厂商和科研机构开始完全用ASIC搭建核心路由器平台的研究，至今已经实现了较为完善的技术体系。

## 防火墙

### 1、什么是防火墙？

**防火墙**（ Firewall ）是防止火灾发生时，火势烧到其它区域，使用由防火材料砌的墙。

![img](https://pic4.zhimg.com/80/v2-2fd0137f949fa1666d7d01dd4b913af7_1440w.webp)

后来这个词语引入到了网络中，把从外向内的网络入侵行为看做是火灾，防止这种入侵的策略叫做**防火墙**。后来，防火墙不但用于防范外网，例如：对企业内网的 DoS 攻击或非法访问等，也开始防范从内部网络向互联网泄露信息、把内部网络作为攻击跳板等行为。

![img](https://pic4.zhimg.com/80/v2-cf6b48e45f64142de49f4ee579815633_1440w.webp)

硬件防火墙可以实现 **CIA** 的**机密性**（ Confidentiality ）、**完整性**（ Integrity ）、**可用性**（ Availability ）这三种类型的对应策略。小企业会在局域网和互联网的边界部署防火墙。

![img](https://pic4.zhimg.com/80/v2-d4228ac8b7a0bb2f4a39c8b9a92baa67_1440w.webp)

### 2、防火墙有哪些类型？

防火墙可分为**软件防火墙**和**硬件防火墙**。软件防火墙又可分为**个人防火墙**和**网关防火墙**。

### 个人防火墙

个人防火墙运行在 PC 上，用于监控 PC 和外网的通信信息。在 Windows 操作系统中集成了 Windows 防火墙。![img](https://pic1.zhimg.com/80/v2-b3e53f344f80937943e6f00010fb0b14_1440w.webp)

杀毒软件产品厂家的个人防火墙一般包含在安全软件套件里。

![img](https://pic4.zhimg.com/80/v2-7a0947bac8a6bdace555959412248c57_1440w.webp)

### 网关防火墙

在网络中的网关上配置防火墙的功能，能对网络中的流量进行策略控制，这就是**网关防火墙**。

网关防火墙分为两种，一种是在 Windows 、Linux 等操作系统上安装并运行防火墙软件的**软件网关防火墙**，另一种是使用专用设备的**硬件网关防火墙**。

个人防火墙主要监控 PC 的通信流量，网关防火墙是监控网络中所有终端的通信流量，在网关处进行策略控制。

![img](https://pic2.zhimg.com/80/v2-25c8d78e392d4f7991ee5be7b3488675_1440w.webp)

### 硬件防火墙

通过硬件设备实现的防火墙叫做**硬件防火墙**，外形跟路由器相似，接口类型通常有千兆网口、万兆光口。

![img](https://pic2.zhimg.com/80/v2-a74876b33e407bb53e95540aa26cf22d_1440w.webp)

### 3、防火墙有哪些技术类型？

![img](https://pic3.zhimg.com/80/v2-82d2e9b5eb83495711789d9833d20726_1440w.webp)

### 4、什么是代理服务器？

**代理服务器**是应用网关防火墙的一种。假设客户端和 HTTP 服务器通信时， 客户端发送请求报文时，代理服务器会替代客户端向 HTTP 服务器发送请求；HTTP 服务器回复响应报文时，代理服务器会代替 HTTP 服务器向客户端回复。对于客户端来说，代理服务器就是 HTTP 服务器。客户端和代理服务器、代理服务器和 HTTP 服务器分别建立两个会话。

- 从客户端收到的请求报文、从服务器收到响应报文，代理服务器都会在应用层进行检查，如果有异常就放弃通信或发送出错信息。
- 由于代理服务器是会话的起点，对互联网的服务器来说，是看不到客户端的 IP 地址。

![img](https://pic3.zhimg.com/80/v2-3cdf291ebeff134076771ee8d49bd842_1440w.webp)

报文过滤防火墙是以 IP 或 TCP/UDP 为对象，判断是否允许通信。而应用网关防火墙是以应用程序为对象，也就是将 FTP 、HTTP 、Telnet 、DNS 等为对象进行判断。

### 5、防火墙有哪些接口模式？

防火墙有四种接口模式，分别是 **L3 模式**、**L2 模式**、**L1 模式**和 **TAP 模式**。

![img](https://pic4.zhimg.com/80/v2-ff9a3548535499340d95f1b62190e9f7_1440w.webp)

L1 ~ L3 模式是将防火墙进行串连，TAP 模式是防火墙进行旁挂。

![img](https://pic2.zhimg.com/80/v2-9642b02ea87ef26ec8bb3d8f02b2af19_1440w.webp)

### 6、防火墙能防范哪些威胁？

防火墙能够防范的威胁如下：

- **窃听**：通过窃听网络数据获取银行卡号、密码等重要信息

![img](https://pic3.zhimg.com/80/v2-67658f37e5bed2b55cce7c0144b24276_1440w.webp)

- **篡改**：将网站主页、邮件等通信内容恶意修改

![img](https://pic4.zhimg.com/80/v2-c8e67dbd4982c9be4948da8ddd0dba43_1440w.webp)

- **破坏**：通过电脑病毒或DoS攻击等破坏系统的正常工作

![img](https://pic2.zhimg.com/80/v2-7e2ccde3bcecce9a1b0601abc4eab0a1_1440w.webp)

- **冒充**：冒充他人发送邮件，对接收方进行钓鱼、诈骗等行为

![img](https://pic1.zhimg.com/80/v2-0e91ee38baa91416b8a3836d07563468_1440w.webp)

- **信息泄露**：电脑或服务器上的重要信息或文档泄露

![img](https://pic1.zhimg.com/80/v2-ad59f3ec9c0648ad6eec04fbbd026ed8_1440w.webp)

- **攻击跳板**：作为病毒部署或DoS攻击的跳板

![img](https://pic4.zhimg.com/80/v2-df788f732f5270defa11439cf1b615ff_1440w.webp)

- **垃圾邮件**：以营利为目的发送大量邮件

### 7、有哪些人会威胁安全？

- **黑客**（ hacker ）：是指精通计算机技术的人，并非特指网络攻击者。
- **破解者**（ cracker ）：对网络进行非法访问、窃听信息、篡改等行为的人。
- **攻击者**（ attacker ）：使用 DoS 等攻击系统，以造成系统宕机为目的的人。
- **妨碍者**：发送大量垃圾邮件、在论坛粘贴大量广告、发布大量无意义信息的人。
- **普通用户**：尽管不会主动攻击，但在病毒、蠕虫等感染电脑后，成为威胁网络安全的对象。
- **僵尸**（ bot ）：作为攻击跳板的终端，被植入具有攻击程序的病毒，遭受感染的终端叫做僵尸，由大量僵尸程序组成的网络叫做僵尸网络。

### 8、防火墙有哪些功能？

防火墙常见的功能有：**会话管理**、**报文结构解析**、**安全区域**、**安全策略**、**NAT** 、**VPN** 、**DoS 防御**、**报文攻击防御**、**内容扫描**、**监控和报告**、**报文抓包**。

### 9、什么是会话？

**会话**是两个终端系统之间的逻辑连接，从开始到结束的通信过程。

在 **TCP** 中，客户端和服务器通信，使用 3 次握手建立 1 个 TCP 连接，客户端发送请求（ request ），服务器进行回应（ response ），直至结束的过程就是进行了 1 个会话通信。

在 **UDP** 中，客户端和服务器的源端口和目的端口一致，之后的一系列通信都叫做会话。

在 **ICMP** 中，Echo request 和对应的 Echo reply 组成 1 个会话。

**数据流**是一组有序，有起点和终点的数据序列。一个会话有两个数据流（ flow ）：一个是 “ 客户端到服务器 ”（ client to server ），另一个是 “ 服务器到客户端 ”（ server to client ）。

![img](https://pic1.zhimg.com/80/v2-e1fb9536189a5dd1c8a3712d1bc6c4ac_1440w.webp)

### 10、什么是 TCP 连接管理？

在数据通信前，客户端发送一个 **SYN 包**作为建立连接的请求。如果服务器发来回应，则认为可以开始数据通信。如果未收到服务器的回应，就不会进行数据通信。在通信结束时，会使用 **FIN 包**进行断开连接的处理。

SYN 包和 FIN 包是通过 TCP 头部的控制字段来管理 TCP 连接。一个连接的建立与断开，正常过程至少需要来回发送 7 个包才能完成。建立一个 TCP 连接需要发送 3 个包，这个过程叫作**三次握手**。断开一个 TCP 连接需要发送 4 个包，这个过程也称作**四次挥手**。创建一个 TCP 连接，会产生一个 32 位随机序列号，因为每一个新的连接使用一个新的随机序列号。

![img](https://pic2.zhimg.com/80/v2-37eab1afd616a03ae5606104fd550c99_1440w.webp)

- **SYN 检查**

TCP 会话开始时，客户端会发送一个 SYN 消息。如果没有会话信息，或尚未建立会话，即非 SYN 消息的 TCP 数据段到达防火墙，防火墙会当做非法消息而丢弃。

- **ACK 检查**

通过对 SYN-ACK 的 ACK 消息检查，确认进行中的 3 次握手是否是非法尝试，防范 SYN Flood 攻击。

- **重复数据段检查**

防火墙收到重复数据段，也就是序列号相同的 TCP 数据段，可以选择接收或者丢弃。

- **窗口检查**

防火墙可以检测 TCP 头部的序列号和滑动窗口大小，拦截超过滑动窗口容量数据的序列号。

- **数据段重组**

防火墙可以验证 TCP 数据段序列号是否完整。

### 11、防火墙如何建立会话？

**a**.防火墙收到报文后，首先检查会话表，确认是否有相同的会话。如果有相同会话，那么会禁止会话建立，确保会话都是唯一的。

**b**.如果是不同会话，那么检查报文，通常是查看路由表或 MAC 地址表来确定转发路径。如果可以转发，就确定对应的转发出接口和目的网段。如果不能转发，就丢弃这个数据。

**c**.报文检查目的地址是否需要进行 NAT 。如果需要，就先完成 NAT ，然后转发到相应出接口和目的网段。

**d**.对报文和目的信息进行安全策略检查，源信息是源接口、源区域和源地址，目的信息是目的接口、目的区域和目的地址。如果有匹配的安全策略，就根据策略进行处理，允许通信就进行转发，拒绝通信就进行丢弃。如果没有匹配的安全策略，就根据默认拒绝的策略丢弃数据。

**e**.当报文被允许通信时，防火墙的会话表中就会生成相应的会话信息。

### 12、什么是会话生存时间？

自动生成的会话表信息，是有一定的**生存时间**。会话建立后，一段时间内一直没有进行通信，防火墙会删除生存时间到期的会话表项。如果长期保留会话表项，这些会话信息可能会被恶意攻击。同时，会话表是会占用防火墙资源，防火墙的会话表项的数量也是有限的，长期保留闲置的会话，会影响新会话的生成。

会话时间可以根据协议的不同，分别进行设置。

TCP 的话，会话的超时时间通常是 30 分钟到 1 小时，UDP 是 30 秒。比如，Telnet 连接在防火墙上建立会话后，如果在 1 个小时内没有任何数据通信，防火墙会自动删除这个会话表项。客户端无法再次使用这个 Telnet 会话了。

![img](https://pic1.zhimg.com/80/v2-a9aa7ca36b87beaa91a479a0ccb18c7c_1440w.webp)

### 13、会话如何正常终止？

客户端完成数据传输后，发送 **FIN** 消息，即使用 FIN 标志位的 TCP 数据段。

服务器收到 FIN 消息后，在回复消息中，使用 FIN 和 ACK 标志位，并将 ACK 编号设置为“接收的 Seq 编号 + 1 ” 。

客户端相同处理方式，在回复消息中，使用 ACK 标志位，并将 ACK 编号设置为“接收的 Seq 编号 + 1 ” 。

如果客户端或服务器在连接过程发生故障，只有一方是侦听状态，这叫做半侦听或**半关闭**。如果通信恢复，接收到故障前的数据段，那么会回复 RST 消息，强制终止 TCP 连接。

当防火墙收到 FIN 或 RST 消息时，会启动一个 30 秒的定时器。即使 FIN → FIN-ACK → ACK 的终止过程没完成，防火墙也会强制删除会话表项。

![img](https://pic1.zhimg.com/80/v2-5480444ebbca7dc4e09d8b4df84d1ee4_1440w.webp)

### 14、什么是 UDP 数据流？

UDP 不需要像 TCP 一样 3 次握手，客户端和服务器直接使用应用程序的 UDP 数据进行交互。

**UDP 数据流**是指源 IP 地址、源端口号、目的 IP 地址和目的端口号这 4 个参数都相同的一系列 UDP 数据。

![img](https://pic2.zhimg.com/80/v2-79626f8b1c598570d58c3fe1a72bc495_1440w.webp)

DNS 和 SNMP 这类应用程序，只需要 1 个 UDP 数据，就能构成 1 个数据流。

音频和视频使用的 RTP ，就需要多个 UDP 数据，来构成 1 个数据流。

### 15、没有端口号的协议如何生成会话？

像 ICMP 这类没有端口号的协议，是直接根据 IP 头部的**协议号**来生成会话。

防火墙通过识别 ICMP 不同的请求消息和对应的响应消息，来判断这些消息序列是否属于同一个会话。

![img](https://pic3.zhimg.com/80/v2-9318e2e745b0965c4bf804c84ebcfbe6_1440w.webp)

### 16、两台防火墙，如何管理会话？

通常两台防火墙会使用主备方式的冗余结构，对主防火墙和备防火墙的会话信息进行**同步**。主防火墙负责建立用户通信的会话，并把会话信息记录到会话表中，同时将信息转发到备防火墙。

### 17、会话管理有什么防御功能？

防火墙可以通过**限制会话数量**，能够防范 DoS 攻击，还能控制防火墙的负载，提高防火墙的性能。

防火墙可以以 TCP SYN 、UDP 、ICMP 等协议为单位，通过指定源与目的的组合方式，来限制这类会话的数目。

### 18、如何防范非法报文？

为了防止非法报文的流入和流出，防火墙会对报文的头部和数据进行解析。常见的有：**IP 头部解析**、**TCP 头部解析**、**UDP 头部解析**。

### IP 头部解析

![img](https://pic4.zhimg.com/80/v2-f4f247c7caa418a96c43ac1aaed4e6bb_1440w.webp)

数据帧和 IPv4 头部的解析内容如下：

**以太网类型与 IP 版本**：以太网数据帧头部的类型字段为 0x0800 时表示 IPv4 ，同时 IPv4 头部的版本也是 4 。类型字段为 0x86DD 时表示 IPv6 ，IP 头部的版本也是 6 。

**IP 头部**：确认数据是否完整，并检查报文长度与实际长度是否一致。

**IP 协议号**、**TTL** ：检查字段值，如果值为 0 就丢弃报文。

**源地址**、**目的地址**：确认是否存在 LAND attack 。

**数据总长度**：确认是否存在 ping of death 攻击。

**标志位**、**分片偏移**：丢弃无法进行分片的报文。

**可选项**：丢弃无用可选项的报文。

### TCP 头部解析

![img](https://pic2.zhimg.com/80/v2-e5830d1f60294a0e1ba25b2d234e27c9_1440w.webp)

TCP 头部的解析内容如下：

**TCP 头部**：确认各个字段是否完整、是否有被中途截断。

**数据偏移**：确认数据偏移字段的值是否是 5 以下，TCP 头部长度最小是 5 字符 = 20 字节。

**校验和**：确认校验和是否错误。

**端口号**：确认源端口号和目的端口号是否为 0 。

**控制位**：检查 SYN 、ACK 等字段是否存在组合不正确的情况。

### UDP 头部解析

![img](https://pic4.zhimg.com/80/v2-fb30ce4e130c8c27dfa0ae095612a083_1440w.webp)

UDP 头部的解析内容如下：

**UDP 头部**：确认各个字段是否完整、是否有被中途截断。

**校验和**：确认校验和是否错误。

### 19、什么是安全区域？

防火墙有**安全区域**（ Security Zone ，简称区域）的概念。防火墙的物理接口和逻辑接口会分配到不同的区域中，也就是将防火墙的网段分别划分到不同的区域中。一个网络接口只能属于一个区域。

在同一个区域内，可以自由进行通信，但是跨区域通信，必须符合安全策略才行。当然，防火墙也可以设置安全策略，根据源或目的地址等条件，判断在同一区域内能否允许通信。

![img](https://pic4.zhimg.com/80/v2-f80aa19a5a0203109cc4f741e10d8077_1440w.webp)

**信任区域**（ Trust Zone ），也叫做内部区域，所属接口是 G1/1 、tunnel1 、Loopback1 ，是指公司内部网络区域，表示可以信赖的区域。通常区域内是可以自由通信。

**不信任区域**（ Untrust Zone ），也叫做外部区域，所属接口是 G1/2 ，是指公司外部网络区域，比如互联网。与信任区域相对，是不可信任的区域，通常只会拦截通信，不允许所有通信。也可以设置安全策略，允许从信任区域到不信任区域的通信。

**DMZ 区域**（ DeMilitarized Zone ），所属接口是 G1/4 ，是对外公开的服务器使用的区域，与信任区域是分开的。

为了防止攻击，从外部网络访问内部网络的通信会被防火墙拦截，但是内部网络中有对外公开的服务器，比如 Web 服务器，对于 Web 请求就不能一刀切的拦截。但如果把服务器放在内部网络中，一旦从外部网络恶意入侵，就会导致内网的重要数据泄露。因此，我们把需要对外公开的服务器放在 DMZ 中，这样即使服务器遭到入侵，DMZ 区域也无法直接访问内部网络。

**自定义区域**（ Custom Zone），这里说的是上图 Sales Zone ，所属接口是 G1/3 ，只有销售部门员工才能访问的区域，是人为划分和定义的自定义区域。当然，也能根据具体内容、安全策略描述和管理目的自定义其它区域。

### 20、什么是安全策略？

防火墙的主要功能是访问控制，也就是判断特定源和特定目的之间是否允许进行特定的通信。访问控制是通过规则来实现，每一条规则都指定了源、目的和通信内容等信息。这些访问控制规则的集合，在路由器中，叫做**访问控制列表**，而在防火墙中，叫做**安全策略**或安全规则。

### 21、路由器的访问控制列表是什么样的？

通常一个规则是由多条**访问控制列表**组成，一条访问控制列表也叫做一个**表项**。一个表项由对象（ object ）、行为（ action ）、选型（ option ）这 3 个元素组成。

举个栗子：思科**标准访问控制列表**，表项只允许源 IP 地址作为对象，而行为是在允许（ permit ）和拒绝（ deny ）之间二选一。当满足条件时，也就是触发对象时，选项可以指定 “ 记录日志 ” 或 “ 表项有效时间 ” 等操作。如果使用了有效时间选项，就可以设置一个只有公司上班时间为对象的表项。

**扩展访问控制列表**，对象就不仅仅是 IP 地址，还可以是 IP 协议号、源 IP 地址、目的 IP 地址、ToS 数据域、ICMP 类型、ICMP 消息、源 TCP/UDP 端口号、目的 TCP/UDP 端口号、TCP 会话是否已经建立等。

举个栗子：允许 IP地址是 10.1.1.2 的客户端向 IP 地址是 172.16.1.1 的服务器进行 Telnet 连接，Telnet 的 TCP 端口是 23 ，访问控制列表如下：

> access-list 101 permit tcp host 10.1.1.2 host 172.16.1.1 eq telnet

### 22、防火墙的安全策略是什么样的？

对比路由器的访问控制列表，防火墙的安全策略最大的不同点是对象，防火墙以**区域**作为对象，还可以以应用程序名称和用户名称等信息作为对象。

![img](https://pic4.zhimg.com/80/v2-9efb5d527da0792291f300f33b3ed8ab_1440w.webp)

举个栗子：在上图的安全策略中，192.168.2.1 从信任区域向不信任区域的 80 端口通信时，防火墙首先执行第 1 条安全策略，发现源地址不匹配，不执行 Allow 。接着执行第 2 条安全策略，发现地址和端口匹配，执行 Deny ，也就是拒绝通信。防火墙的安全策略从上往下依次执行的行为，也叫做**安全策略查找**（ policy lookup ）。

**Any** 表示任何值都与策略匹配。如果是安全策略中，出现未定义的通信，比如从信任区到 DMZ 区域的通信，防火墙默认执行拒绝，这个策略叫做 “ **默认拒绝** ”（ implicit deny ）。

如果需要在防火墙没有匹配的情况下，执行 Allow ，可以在安全策略的最后一行设置对象为 Any ，行为为 Allow 的策略。

![img](https://pic4.zhimg.com/80/v2-3650f272cd9ae5a5db8c19ae692d1947_1440w.webp)

当然，防火墙的安全策略是会有上限，上限由产品规格决定。而且当表项越多时，设备性能也会随之下降。

### 23、什么是内容安全策略？

防火墙不仅能够基于区域、IP 地址、端口号、应用程序等设置安全策略，还可以使用**内容安全策略**进行通信控制。内容安全策略包括**反病毒**、**IPS**（入侵防御系统）、**URL 过滤**、**DLP**（数据泄露防护）等基于内容的安全机制，能够拦截非法通信和避免不必要的通信流量。还可以对这些通信不进行拦截，而是记录到告警日志中后放行。

安全设备的默认设置是拦截严重程度高的攻击，严重程度低的攻击只记录到告警日志中。当然，严重程度的高低可以自定义，也可以修改设置为拦截严重程度低的攻击。

反病毒和 IPS 可能会出现误判，误判分为**假阳性错误**和**假阴性错误**两种。

**假阳性错误**是没有攻击行为或病毒入侵，但是被判定为攻击行为或病毒入侵，并记录到日志中，或把通信拦截。这类错误，用户容易察觉。

**假阴性错误**是存在攻击行为，却判定没有攻击行为，而允许通信，也没有记录到日志中，无法察觉到严重后果。只有 PC 上安装反病毒软件或防火墙软件，才能找到没有被识别的攻击行为。这种错误一般是由于数字签名本身不存在，或误认为数字签名存在而导致的检测失败。

### 24、什么是 NAT ？

私有 IP 地址只能在内部网络通信，如果要访问外部网络（互联网），可以通过路由器或防火墙把私有 IP 地址转换为公网 IP 地址，这个过程叫做 **NAT**（ Network Address Translator ）。

NAT 以前是路由器的功能，后来位于网络边界的防火墙也常常使用这个功能。路由器和防火墙等运行 NAT 功能后，也叫做**网关**（ gateway ）。

### 静态 NAT

**静态 NAT**（ Static NAT ）是指 NAT 转换前的地址和 NAT 转换后的地址是一对一的对应关系，通常是一个私网地址对应一个公网地址，手动将对应信息配置到网关中。

![img](https://pic2.zhimg.com/80/v2-a9f506d069ff0195ced2ce24d9b48e09_1440w.webp)

### 动态 NAT

**动态 NAT**（ Dynamic NAT ）是在网关配置一个 IP 地址池（ IP address pool ），地址池里面包含多个 IP 地址。在 NAT 建立会话时，在地址池内的 IP 地址按顺序分配一个转换后的 IP 地址。由于地址范围能够手动进行设置和更改，因此这种方式应用的比较多。

![img](https://pic1.zhimg.com/80/v2-864b051c5e55a0326de37e3b902551b0_1440w.webp)

虽然和静态 NAT 有点类似，私有地址和公网地址是一对一的映射关系，但不是指定的 NAT 转换后地址，而是动态分配的、在 IP 地址池中排序靠前的有效地址。

### 源 NAT

**源 NAT**（ Source NAT ）是对发送方的源 IP 地址进行 NAT 转换。在公司内部网络的客户端，要访问互联网的服务器，客户端的私有地址作为发送源，把数据发送到网关时，必须将私有 IP 地址转换成公网 IP 地址才行。

![img](https://pic2.zhimg.com/80/v2-5b0b343b439f8ad7c3bb9a88e23ebb8d_1440w.webp)

要和互联网上的服务器进行通信，必须使用公网 IP 地址，但是 IPv4 地址有限，无法为每台客户端都分配一个公网地址。大部分情况下，源 NAT 能够通过动态 NAT 方式节约公网地址资源。在网关上设置地址池，或在网关的接口使用 NAPT ，可以实现私有网络访问互联网的功能。

外部网络只能看到公网地址信息，源 NAT 能够隐藏客户端实际使用的 IP 地址，从而降低受到外部网络攻击的风险。

### 目的 NAT

**目的 NAT**（ Destination NAT ）是接收到的目的 IP 地址进行 NAT 转换。

![img](https://pic2.zhimg.com/80/v2-a9f506d069ff0195ced2ce24d9b48e09_1440w.webp)

互联网的客户端，想要通过网关访问内部网络的服务器时，由于公司内部服务器使用内网地址，无法直接从互联网访问到，需要进行目的 NAT 。网关作为内部服务器的代理，把服务器的内网地址映射到公网地址，收到外网客户端访问公网地址时，网关将报文的目的地址转换为内部服务器的私有地址，完成路由和访问。公司内的服务器通常放置在 DMZ 区域中，能够对外部网络屏蔽内部服务器的地址，从而避免内部网络受到攻击。

### NAPT

当有大量的内网客户端要跟外网通信，而公网地址只有一个或者少量时，网关无法完成私有地址和公网地址的一对一的分配。

![img](https://pic3.zhimg.com/80/v2-8da6b4e7c65c5bf3ddfdeb82f60f2e92_1440w.webp)

这时，网关需要结合 TCP 或 UDP 端口号，完成多个私有地址映射成一个公网地址的转换，这种转换方式叫做 **NAPT**（ Network Address Port Translation ，网络地址端口转换）。

### 25、什么是 VPN ？

**VPN** ，全称是 Virtual Private Network ，也就是虚拟私有网络。VPN 是使用电信运营商提供的公共网络，搭建内部网络的技术。

内部网络的财务、人事等数据，对外而言是属于机密信息，必须在内部封闭的传输数据。如果只有一个办公场所，可以通过 LAN 搭建内网。但如果北京和上海都有分支机构时，就需要在不同的办公场所之间搭建内网。电信运营商有专线服务，可以完成不同地域的内网搭建。专线是单独使用的线路，不用担心数据被窃听，通信质量也能得到保证，但是专线费用昂贵。

还有 ADSL 这种互联网接入服务，虽然属于共享类型网络，但是价格低廉，搭建内网有成本优势。路由器、防火墙、VPN 设备都支持 IPsec-VPN 功能，在各个分支机构内，使用这些设备建立 IPsec 隧道，完成 VPN 的搭建。

### 26、VPN 有哪几种网络拓扑？

常见的 VPN 网络拓扑有点对点 VPN 、中心型 VPN 、远程接入 VPN 。

- **点对点 VPN**

点对点 VPN（ site-to-site VPN ）是通过 IPsec 隧道连接两个网络的拓扑结构。网络的网关，通常是路由器或防火墙等网络设备，在两个网络间，使用点对点的拓扑结构，建立 IPsec 隧道。

![img](https://pic3.zhimg.com/80/v2-2f4746825ea80421c28a39177139af56_1440w.webp)

这里的网络，是指不在同一个局域网的网络，比如：成都机构或广州总部的任意一个站点。因为是站点（ site ）之间的连接，所以叫做点对点 VPN 。

- **中心型 VPN**

中心型 VPN（ hub and spoke VPN ）是星型拓扑结构，也就是一个中心站点的设备，连接多个远程站点的设备，形成的网络结构。中心站点（ center site ）位于总部的网络，也就是数据中心，成为整个结构的核心站点。一般是电信供应商提供的 VPN 业务，以电信供应商的基础设施为中心站点，通过 VPN 连接其它站点。

![img](https://pic3.zhimg.com/80/v2-14f27334cc1d7237a6fbdfae568e2c0a_1440w.webp)

- **远程接入 VPN**

在家里，或出差在外时，通过互联网使用 PC 上的软件，与公司的 VPN 设备建立 IPsec 隧道，能够访问公司内部网络的拓扑结构，叫做远程接入 VPN 。

![img](https://pic2.zhimg.com/80/v2-5daf377ac9fc9286d97e5155f728e8ed_1440w.webp)

远程接入的 IPsec-VPN 需要在 PC 上安装 VPN 客户端软件，而 SSL-VPN 是通过 Web 浏览器，使用 SSL 连接到公司的 VPN ，通过 SSL（ HTTPS ）和公司的内部网络进行连接。

### 27、IPsec VPN 有哪些专用名词？

**SA**（ Security Association ）：IPsec 通信时建立的逻辑连接。

**ESP**（ Encapsulating Security ）：原始报文使用 DES/3DES/AES 中的任意一种算法进行加密，通过 HMAC 确定数据是否被篡改，使用的 IP 协议号是 50 。

**AH**（ Authentication Header ）：根据 HMAC 信息确定报文是否被篡改的认证协议。不对报文加班，使用的 IP 协议号是 51 。

**IKE**（ Internet Key Exchange ）：IPsec 协议用来交换 key 信息的协议，也叫做 ISAKMP/Oakley 。在 ISAKMP 协议上实现 Oakley 的 key 交换过程。使用的是 UDP 端口号 500 。分为阶段一和阶段二进行处理。

**HMAC**（ Keyed-Hashing for Message Authentication code ）：用来验证信息是否被篡改的一种 MAC ，也就是消息认证码，通过散列函数与密钥信息的组合计算得出，其中散列函数使用的算法一般是 MD5 或 SHA-1 。

**SPI**（ Security Pointer Index ）：表示 SA 的编号，32 比特。在对报文加密时，用这个值表示使用了什么加密算法和密钥信息。

**NAT traversal** ：通过 ESP 加密的报文，由于没有 TCP/UDP 头部，因此无法使用 NAPT 。可以使用 NAT traversal 技术，给 ESP 加密后的报文添加 UDP 头部，从而在 NAPT 环境下进行 IPsec 通信。一般使用 500 或 4500 的端口号。

**IPsec-VPN 连接**：在建立 IPsec 隧道时，发起协商的叫做发起方（ initiator ），另一方叫做应答方（ responder ）。发送方是最先发出通过 IPsec 隧道报文的设备。

**更新 key**（ rekey ） ：IPsec 隧道建立后，每过一段时间，或经过一定量的数据，就会进行 rekey 操作。VPN 设备有修改 rekey 时间的功能。

### 28、点对点 VPN 的处理过程是什么样的？

**举个栗子**：网络 A 与网络 B 通过 IPsec 隧道连接时，网络 A 的 PC1 想和网络 B 的 PC2 进行通信。

![img](https://pic2.zhimg.com/80/v2-97f9478106b9817f46a0a663ea3833d1_1440w.webp)

PC1 发送请求，到达网络 A 的网关，也就是 VPN 设备 A ，这时的报文还未加密，是明文状态。VPN 设备 A 对报文进行加密，并添加 ESP 头部和在隧道中使用的 IP 头部（叫做外层 IP 地址），再通过 IPsec 隧道发送出去。

网络 B 的 VPN 设备 B 通过 IPsec 隧道收到加密的报文，会检查 ESP 头部和 AH 头部。如果 ESP 序列号不正确，VPN 设备 B 就会认为是重放攻击，并输出错误信息，SPI 值不正确，会输出 “ Bad SPI ” 的错误通知信息。

如果加密报文正常，就进行解密操作，去除外部 IP 、ESP 、AH 等头部，并对原来 IP 头部的目的地址进行路由，从而到达 PC2 。

PC2 向 PC1 回复消息时，由 VPN 设备 B 进行加密处理，由 VPN 设备 A 进行解密处理。

中心型 VPN 的远程站点客户端和中央站点服务器的 VPN 通信也是这种处理流程。

### 29、远程站点之间的通信过程是什么样的？

**举个栗子**：远程站点 A 、远程站点 B 和中央站点 VPN 设备 C 。A 的 PC1 和 B 的 PC2 进行通信。

![img](https://pic4.zhimg.com/80/v2-8d066ba574952df78bffc67581279f17_1440w.webp)

报文通过 VPN 设备 A 和 VPN 设备 C 的 IPsec 隧道，再经过 VPN 设备 C 和 VPN 设备 B 的 IPsec 隧道，最终到达 PC2 。

如果中央站点是路由器或 VPN 设备，一般只会解密、加密和路由选择处理。如果中央站点是防火墙，就会在报文解密后进行检查，只对安全的报文进行加密，然后再向远程站点发送。

### 30、什么是基于策略的 VPN ？

路由器和 VPN 设备通常使用基于策略的 VPN 。**基于策略的 VPN** 是指根据策略（访问控制列表）控制经过 IPsec 隧道的流量，这样即使路径发生变化，也不会对 IPsec 通信造成影响。

基于策略的 VPN 需要设置 IPsec 策略和 proxyID 信息。proxyID 指定 IPsec 隧道传输报文的本地网络和远程网络。

**举个栗子**：站点 A 和站点 B 使用点对点 VPN 组成网络，其中站点 A 网络是 192.168.1.0/24 和 192.168.2.0/24 ，站点 B 网络是 192.168.3.0/24 和 192.168.4.0/24 。如果只有 192.168.1.0/24 和 192.168.3.0/24 进行加密通信，那么在站点 A 的 VPN 设备设置本地 proxyID 为 192.168.1.0/24 ，远程 proxyID 为 192.168.3.0/24 。在站点 B 的 VPN 设备设置本地 proxyID 为 192.168.3.0/24 ，远程 proxyID 为 192.168.1.0/24 。

![img](https://pic4.zhimg.com/80/v2-b5ba121d246a4b8375e6172908e0b1b3_1440w.webp)

### 31、什么是基于路由的 VPN ？

**基于路由的 VPN** 通常是防火墙产品使用的 VPN 类型。防火墙会对 IPsec 报文进行精确的控制。

在基于路由的 VPN 中，IPsec 隧道是使用的虚拟接口，又叫做隧道接口（ tunnel interface ），流量通过这个接口进入 IPsec 隧道。如果有流量需要在 IPsec 隧道内传输，可以设置路由选择，转发到隧道接口就行。

基于策略的 VPN 使用策略来控制 IPsec 通信的流量，而基于路由的 VPN 通过隧道接口的路由信息来控制 IPsec 通信的流量。所以在进行 IPsec 通信时，可以和处理普通报文一样，通过策略定义报文过滤和防火墙处理等。

### 32、什么是阶段 1 ？

在 IPsec 通信中，为了建立加密隧道的 SA ，需要在设备之间使用 IKE 协议完成密钥的交换。

为了提高安全性，IKE 协议分为**阶段 1** 和**阶段 2** 两个部分。**IKE 阶段 1** 是完成鉴别和保护 SA 通信的双方，同时生成阶段 2 需要的公有密钥，建立 IKE SA 等工作。

![img](https://pic3.zhimg.com/80/v2-9a9940e2195ce3fe82016eb23b136c2a_1440w.webp)

### 33、什么是阶段 2 ？

**IKE 阶段 2** 负责生成 IPsec 通信使用的密钥，并建立 IPsec SA 。

![img](https://pic4.zhimg.com/80/v2-1fe8e0dbfa2d4a7eb987730d190bc54f_1440w.webp)

### 34、什么是 SSL-VPN ？

**SSL-VPN** 是通过浏览器使用 HTTPS（ HTTP over SSL ）进行 Web 访问的远程接入 VPN 。

如果要使用 IPsec-VPN ，需要在 PC 上安装专用的客户端软件。这个客户端软件不一定支持 Mac OS 、手机等操作系统。同时 IPsec-VPN 连接过程，可能会因为防火墙过滤了 IPsec-VPN 的协议号或 NAT traversal 的端口号，而导致连接失败。

SSL-VPN 就方便很多，只要设备带有浏览器，就能够通过反向代理的方式完成 VPN 的连接。而且防火墙几乎不会拦截，因为使用的是 HTTPS 的 443 端口，让 VPN 远程连接摆脱了操作系统和连接方式的限制。

![img](https://pic3.zhimg.com/80/v2-82243a4f0e96638306a41720d3c38e32_1440w.webp)

IPsec-VPN 是在网络层实现的，能够完成传输层 TCP 和 UDP 的加密和隧道传输处理。而 SSL-VPN 是在会话层实现的，基于 TCP 的 443 端口运行。只有特定的几种 TCP 能够使用反向代理和端口转发方式，而 ICMP 和 UDP 等传输层通信，只能选择隧道方式。

![img](https://pic1.zhimg.com/80/v2-1f6886ec2931eb8ac96b076c62f02980_1440w.webp)

### 35、什么是反向代理？

**反向代理**，又叫做无客户端 SSL-VPN 。SSL-VPN 的终端在 443 端口号上，通过 HTTPS 完成解密工作后，转换为 80 端口号的 HTTP 通信，与内部网络上的 Web 服务器进行交互。这种方式只有使用 80 端口号、通过浏览器访问 Web 的应用程序才能使用。

在内部客户端访问互联网时，进行中继的代理服务器，叫做**转发代理服务器**。如果访问方向相反，也就是在互联网上的客户端访问内部网络服务器时，进行中继的代理服务器叫做**反向代理服务器**（ reverse proxy ）。

### 36、什么是端口转发？

**端口转发**，又叫做瘦客户端 SSL-VPN 。使用 ActiveX 或 Java applet 等浏览器插件来创建 PC 和服务器的 SSL 隧道。用户只要登录 Web 门户（ SSL-VPN 网关），并完成认证，就能够下载相关插件。用户能够使用公司内网服务器上的特定应用程序，也能够使用端口固定且无需浏览器支持的 TCP 应用程序，比如 E-mail 。有些产品还能够支持端口号变动的应用和 UDP 应用程序等。

### 37、什么是隧道？

**隧道**方式是使用 SSL-VPN 客户端软件的方式。和 IPsec-VPN 一样，支持网络层以上协议的隧道传输。

用户通过浏览器访问 SSL-VPN 设备，并完成认证，就可以下载应用程序，并安装在用户的 PC 上。接下来就是通过客户端软件建立 PC 和 SSL-VPN 设备的隧道。由于使用了客户端软件，还是会不可避免的受到操作系统的限制。

![img](https://pic4.zhimg.com/80/v2-530b89202cd12a42ad8655fe11afa433_1440w.webp)

### 38、什么是主机检查？

支持**主机检查**（ Host Checker ）功能的 SSL-VPN ，在客户端与 SSL-VPN 设备连接时，能够对连接的客户端主机进行检查，检查信息如下图。

![img](https://pic2.zhimg.com/80/v2-df561cee3360b7668c34bf3ab22d61b1_1440w.webp)

如果主机检查结果 OK ，就允许客户端的 SSL-VPN 连接，就能够从外部网络访问公司内网。如果结果是 NO ，就拒绝客户端的 SSL-VPN 连接，或只能进行软件升级等特定范围的访问操作。

### 39、什么是 DoS 攻击？

**DoS** 全称是 Denial of Service ，也就是无法继续提供服务的意思。这里的服务是指服务器的应用程序服务，比如客户端发起 HTTP 请求时，服务器能够发出 HTTP 响应就说明完成了 HTTP 服务。DoS 攻击是针对服务器和网络设备发起的攻击，制造远超预先设计的访问量，让服务器和网络设备无法正常的回复响应报文，导致被攻击的系统无法提供服务。DoS 攻击也可以利用操作系统或程序的安全漏洞等，以少量流量使系统发生异常。在 DoS 中，通过僵尸网络的多个跳板，对服务器发起攻击的方式叫做 **DDoS**（ Distributed Denial of Service ）攻击。

### 40、DoS 攻击有哪些类型？防火墙有什么防范措施？

**Syn Flood** ：发送大量 TCP SYN 报文，导致服务器资源消耗过度，一段时间内无法提供服务的状态。在防火墙内，定义每秒允许通过的 SYN 报文数量，当网络中的 SYN 报文超过这个值时，就会执行 SYN Cookie 的策略。SYN Cookie 策略是当服务器收到客户端的 SYN 报文时，不建立 TCP 连接，而是将 TCP 头部内容的散列值当做序列号放入 SYN-ACK 报文中返回。之后收到包含正确响应编号的 ACK 报文时，才将会话信息存储在内存中，有效防止攻击对服务器内存的消耗。

**ICMP Flood** ：也叫做 ping flood ，发送大量的 ICMP echo request 报文来消耗服务器内存，让服务器暂时无法提供服务。防火墙通过定义一秒内允许的最大 ICMP 报文数量，对超过这个值的 ICMP 报文暂时不处理。

**UDP Flood** ：发送大量的 UDP 报文来消耗服务器的内存，使得服务器暂时无法提供服务。防火墙通过定义一秒内允许的最大 UDP 报文数量，对超过这个值的 UDP 报文暂时不处理。

**IP Flood** ：发送大量的 IP 报文来消耗服务器的内存，使得服务器暂时无法提供服务。防火墙通过定义一秒内允许的最大 IP 报文数量，对超过这个值的 IP 报文暂时不处理。

**Land** ：发送源地址和目的地址相同的报文。受到这种攻击、又有安全漏洞的设备，会不断向自己转发数据而导致宕机。防火墙对于这类报文，一律丢弃。

**Tear Drop** ：发送伪造的、含有 offset 的非法 IP 分片报文。这类攻击对于有安全漏洞的设备而言，会发生无法重新生成报文的现象发生，导致宕机。防火墙对于这类报文，一律丢弃。

**Ping of Death** ：发送超过 IP 报文最大长度 65535 的 ping 。这类攻击对于有安全漏洞的设备而言，会导致无法运行的情况发生。防火墙对于这类报文，一律丢弃。

**Smurf** ：把攻击对象的地址设置成源地址，并广播发送 ICMP echo request 报文，使得攻击对象收到大量 ICMP echo reply 报文而消耗带宽资源。

**Fraggle** ： 同 Smurf 类似，UDP 替代 ICMP 发起攻击，同时利用 echo 、Chargen 、daytime 、qotd 等多种端口。防火墙一般关闭这类端口，或使用安全策略进行拦截。

**Connection Flood** ：反复生成大量长时间为 open 状态的连接，占据攻击对象的 socket 资源。如果服务器端没有最大连接数目的限制，就会发生系统崩溃。

**Reload** ：在 Web 浏览器中连续按下 F5 键，让 Web 页面反复执行刷新操作，也叫做 F5 攻击。在 Web 通信量大时，会让服务器负载加重。

### 41、如何防御 DoS ？

**防御 DoS** 就是限制异常高速通信流量，一般通过设置区域、网络接口、网络等单位来实现。

DoS 防御也可以拦截含有非法内容或安全性低的报文，这类报文让防火墙或路由器处理的话，会导致资源的浪费，因此需要使用专门的 DoS 防御功能来阻挡这类攻击。

### 42、什么是端口扫描？

攻击者在发起攻击前，会对攻击对象的设备情况进行调查，最基础也是最常用的手段就是**端口扫描**（ port scan ）。端口扫描可分为 TCP 端口扫描和 UDP 端口扫描两大类，对 TCP 端口和 UDP 端口按照顺序发送报文，探测目的设备是否开启了对应的服务。比如，某台设备的扫描结果是开启了 22 号端口，攻击者就会知道设备开启了 SSH 服务，从而利用 SSH 服务访问这个设备，并发起后续攻击。

防火墙能够探测出端口扫描行为，可以阻断这个行为。

### 43、端口扫描有哪些类型？

**TCP 端口扫描**：对 TCP 的 0 ~ 65535 号端口全部进行扫描，或在一定范围内扫描端口，从而探测服务器有哪些端口可以使用。扫描过程是向服务器发送 TCP（ SYN ）分组，如果收到了响应 TCP（ SYN + ACK ）报文，那么说明端口是打开状态。如果端口关闭，就会从服务器收到 TCP（ RST + ACK ）报文。

![img](https://pic4.zhimg.com/80/v2-f9c3c1eb3c6cf6d47a4424e3f7cbcb0b_1440w.webp)

**SYN 端口扫描**：属于 TCP 端口扫描的一种，无需完成 3 次握手，直接针对 SYN 报文进行端口扫描，也叫做半扫描。在 3 次握手过程中，根据服务器回复的是 ACK 报文还是 RST 报文来判断端口是否打开。

**ACK 端口扫描**：为规避防火墙对 SYN 端口扫描的检测，向服务器发送 ACK 报文，根据回复的 RST 报文窗口大小来判断端口是否打开。只对端口打开或关闭时发送不同窗口大小报文的服务器有效。

![img](https://pic1.zhimg.com/80/v2-8300d4e3884c255e0903521d65a27944_1440w.webp)

**Null 端口扫描**：向服务器发送 TCP 头部所有字段为 0 的报文，通过服务器是否返回 RST + ACK 报文来判断服务器端口是否打开。

**FIN 端口扫描**：向服务器发送 FIN 报文，根据是否收到 RST + ACK 报文来判断端口是否打开。

**Xmas 端口扫描**：向服务器发送 TCP 头部所有字段为 1 的报文，根据是否收到 RST + ACK 报文来判断端口是否打开。

**UDP 端口扫描**：对 UDP 的 0 ~65535 号端口全部进行扫描，或是在一定范围内扫描端口，从而探测服务器有哪些端口可以使用。

**Host Sweep** ：向大量主机发送 ICMP 报文或 TCP 报文，如果返回应答，就根据返回的应答报文判断主机是否存在，并得知主机上运行了哪些应用程序等信息。TCP SYN Host Sweep 会同时向多台主机的相同端口发送 TCP SYN 报文。

### 44、有哪些非法报文攻击？

**IP 地址欺骗**（ IP Spoofing ）：为了通过防火墙，避免被监控日志记录，伪造 IP 头部中源 IP 地址的攻击方式。

**分片报文**：分片的 IP 报文，由于安全性弱，常用于攻击，因此防火墙会有拦截分片报文的功能。如果报文和通信链路的 MTU 大小一致，就不会发送分片，这个功能也不会影响正常的通信。

**ICMP 分片**：跟 IP 分片报文类似，防火墙也有拦截 ICMP 分片报文的功能。

**巨型 ICMP 报文**：防火墙通过拦截一定大小以上的 ICMP 报文，就能避免 Ping of Death 攻击。

**非法 ICMP 报文**：如果接收的 ICMP 报文中，头部出现未定义的值时，需要进行额外的异常处理。防火墙会对这类非法的 ICMP 报文进行拦截。

**SYN 以外的 TCP 报文控制**：TCP 会话开始前，会发送 SYN 报文。如果在未确认的 TCP 会话中，收到了除 SYN 以外的字段位是 1 的 TCP 报文，很有可能就是端口扫描等攻击，就需要通过防火墙拦截这类报文。

### 45、什么是 IDS/IPS ？

**IDS** ，全称 Intrusion Detection System ，即入侵检测系统。IPS ，全称 Intrusion Prevention System ，即入侵防御系统，合称为 IDS/IPS 。

IDS 负责检测非法入侵，并告知系统管理员，而 IPS 是通过设置对非法入侵使用的协议和应用程序进行拦截。

IDS/IPS 能够检测的威胁有：

- DoS 攻击
- P2P 造成的信息泄露
- 运行蠕虫、特洛伊木马、键盘记录器等恶意软件
- 入侵局域网和入侵侦查行为

当 IDS/IPS 检测到入侵行为后，会进行相应处理：

- 通知管理员，通过电子邮件或 SNMP 等方式
- 记录日志
- 拦截通信，向攻击方发送 TCP RST 报文

### 46、什么是 Deep Inspection ？

防火墙的 **Deep Inspection** 功能，能够针对特定的应用层协议，重组应用程序数据流的 TCP 数据段，检测其中是否包含了非法应用程序参数。

![img](https://pic2.zhimg.com/80/v2-f11c9ed5f4cdb90f864ca541465aa2fd_1440w.webp)

### 47、IDS/IPS 和 Deep Inspection 能够检测和拦截哪些类型的攻击？

**信息泄露**：攻击者利用带有恶意脚本的邮件，或附带恶意软件的 URL 地址发起的攻击。攻击成功的话，能够获取对方的机密信息。

**执行代码**：向服务器发送非法数据，让服务器接受并执行远端的代码。

**DoS 攻击**：发送大量报文，让服务器的 CPU 、内存使用率上升，妨碍服务器正常提供服务的攻击。

**缓存溢出**（ Buffer Overflow ）：通过恶意程序诱导服务器运行内存超过上限，导致缓存溢出的攻击。

**SQL 注入**：针对 Web 应用程序，使用数据库 SQL 语言，对数据库进行非法操作的攻击。

**暴力破解**（ Brute Force Attack ）：也叫循环攻击，使用密码字典等工具，反复尝试管理员密码的攻击。为了防止这类攻击，需要执行输错 3 次密码就切断会话的类似策略。

**跨站脚本攻击**（ Cross-site Scripting ）：简称 CSS 或 XSS 。利用 Web 应用程序的漏洞，在提交页面表单时，通过服务器执行携带 HTML 标签的脚本，到达劫持会话或钓鱼的目的。

**exploit 攻击**：利用软件安全漏洞发起的攻击中使用的程序或脚本。

**浏览器劫持**：通过操作携带恶意软件的浏览器，在用户浏览 Web 页面时，篡改显示的页面形式和内容。一般会导致持续弹出广告栏、自动添加 URL 连接、跳转其它网页失败的情况。

**钓鱼**：使用伪造官方网站站点 URL 连接的邮件或网站，骗取用户的个人信用卡和银行账号信息。

**僵尸网络**：通过僵尸程序感染多台 PC ，并根据攻击方命令，同时发送垃圾和实施 DoS 等攻击。主要通过使用 IRC 对僵尸下达攻击命令。

### 48、什么是 CVE ？

**CVE**（ Common Vulnerabilities Exposures ，通用漏洞披露）是美国非盈利机构 MIRTE 公司识别已知漏洞的项目。机构会为发现的安全漏洞问题分配一个 CVE 识别编号（ CVE-ID ），当安全厂家提供多个漏洞防范对策时，通过使用这个编号告知用户是哪个安全漏洞问题。以 “ CVE-(公元纪年)-(4字符编号) ” 的格式记录，表明使用这个编号的安全漏洞问题已经广为人知。

![img](https://pic2.zhimg.com/80/v2-90b67e33bdf9565d1c7d87c74fbd32dd_1440w.webp)

### 49、什么是反病毒？

**反病毒**也叫做防病毒策略，通过在个人电脑和服务器上安装防病毒软件，来保护设备免遭病毒侵袭。

在终端上安装防病毒软件的方式叫做**主机型防病毒**。而通过互联网网关的防火墙以及专用设备，对网络上所有的通信数据进行扫描的方式叫做**网关型防病毒**。使用网关型防病毒，能够防止局域网中病毒的蔓延以及跳板机攻击网络的发生。

![img](https://pic2.zhimg.com/80/v2-7bda238698f1596356a59db0f8521659_1440w.webp)

![img](https://pic1.zhimg.com/80/v2-0a935fb841efbb3a3041966b3c862798_1440w.webp)

确认是否存在病毒的操作叫做**扫描**。主机型防病毒的扫描是在主机内进行，而网关型病毒的扫描在通信流量中完成。

### 50、什么是反垃圾邮件？

**垃圾邮件**是指骚扰邮件、广告邮件和诈骗邮件等，很多产品都有过滤这类垃圾邮件的反垃圾邮件功能，但是反垃圾邮件很容易引发误检。有可能出现正常邮件归档到骚扰软件中，误以为没收到邮件，这个需要注意。

### 51、什么是 DLP ？

**DLP** ，全称 Data Loss Prevention ，也就是防范信息泄露功能。

这个功能是检测网络中交换的应用程序数据，当发现特定文件或数据时，及时执行告警、断开会话、记录日志等操作。主要由文件过滤和数据过滤两个部分组成。

![img](https://pic3.zhimg.com/80/v2-db189b1821d28ddd2816bd14e77ae322_1440w.webp)

### 52、什么是 URL 过滤？

**URL 过滤**功能是在 HTTP 通信中，当客户端向服务器发起请求时，能够对 URL 信息进行检查，判断 URL 能否访问，并对有害的 Web 站点进行拦截的功能，通常作为服务器上的软件、防火墙和代理服务器的功能之一，提供给用户。

### 53、防火墙有哪些监控功能？

防火墙有监控、告警通知、日志记录和报告等监控功能。

**监控**（ monitoring ）：对网络和网络设备的实时状态进行监控，及时观察流量状态和故障信息，当发生故障、异常情况时，能够及时告警通知管理员。

**告警通知**（ alerting ）：发生故障和出现定义事件时，向管理员发生告警通知。告警方式可以是发送 SNMP Trap 、向 Syslog 服务器发送 syslog 通信和向服务器发送电子邮件等。

**日志记录**（ logging ）：记录流量日志、事件日志等各类日志的功能。日志能够导出为纯文本格式、CSV 格式、PDF 格式等。

**报告**（ reporting ）：通过 Web 对日志进行加工处理，提供一目了然的图表等信息。有些防火墙是发送 Syslog 日志或专用日志到管理服务器，在管理服务器上展示报告。

### 54、什么是报文抓包功能？

有些安全设备有**报文抓包**功能。抓到的报文可以在设备上流量，也可以导出为 WinPcap 格式的文件，在 Wireshark 这个应用程序中进行浏览。当发生通信故障时，可以根据抓包的信息进行分析。

![img](https://pic3.zhimg.com/80/v2-7375385c71242b20711e4ac41474259e_1440w.webp)

### 55、防火墙性能有哪些要素？

**同时在线会话数**：防火墙通过管理会话表，以会话为单位来控制通信流量。会话表能够记录的表项数目说明了防火墙能够处理的同时在线会话数量。小型防火墙设备一般管理几万个会话，而电信服务供应商使用的防火墙能够同时管理数百万个会话。

**NAT 表数目**：有些防火墙或路由器会分别维护会话表和 NAT 表。NAT 表的数量表示同时在线 NAT 的会话数，这个数值表示设备能够建立 NAT 会话数的最大值。没有 NAT 表数上限的防火墙，一般使用会话数的上限。

**每秒新建的会话数目**：路由器的性能一般使用每秒能够传输的 bit 数 bit/s 和每秒转发报文数 pps 这两个参数来描述。而防火墙还增加了一条每秒新建会话数这个参数，表示在 1 秒内能够完成多少次完整的会话建立过程。1 个完整的会话建立过程包括：监控 TCP 连接的 3 次握手，握手正常则生成会话信息，将信息记录到会话表等操作。也引入另一个指标，表示在 1 秒内能够完成会话从建立到结束的次数，这个指标叫做每秒连接数。

